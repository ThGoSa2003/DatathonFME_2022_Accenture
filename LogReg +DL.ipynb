{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.004443,
     "end_time": "2022-11-11T08:46:48.019499",
     "exception": false,
     "start_time": "2022-11-11T08:46:48.015056",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Sarter Notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "papermill": {
     "duration": 1.688634,
     "end_time": "2022-11-11T08:46:49.712044",
     "exception": false,
     "start_time": "2022-11-11T08:46:48.02341",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import math\n",
    "import haversine as hs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.003519,
     "end_time": "2022-11-11T08:46:49.719635",
     "exception": false,
     "start_time": "2022-11-11T08:46:49.716116",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Reading Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "papermill": {
     "duration": 0.383908,
     "end_time": "2022-11-11T08:46:50.10727",
     "exception": false,
     "start_time": "2022-11-11T08:46:49.723362",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# read train data\n",
    "df_orders = pd.read_csv(\"Datasets/orders.csv\", sep=\";\")\n",
    "df_products = pd.read_csv(\"Datasets/product_attributes.csv\", sep=\",\")\n",
    "df_dists = pd.read_csv(\"Datasets/cities_data.csv\", sep=\";\")\n",
    "df_ordersXproducts = pd.read_csv('Datasets/ordersXproducts.csv')\n",
    "del df_ordersXproducts['Unnamed: 0']\n",
    "\n",
    "# read test data\n",
    "df_test = pd.read_csv('Datasets/finaltest.csv')\n",
    "df_test['weight'] = df_test['weight'].fillna(df_test['weight'].mean())\n",
    "df_test['late_order'] = True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Merge tables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_coord = df_dists[['city_from_name', 'city_from_coord']].drop_duplicates().reset_index().drop(columns=['index']).copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_alt = df_dists.copy()\n",
    "\n",
    "c2 = df_alt['city_from_name'].values.copy()\n",
    "c1 = df_alt['city_to_name'].values.copy()\n",
    "c4 = df_alt['city_from_coord'].values.copy()\n",
    "c3 = df_alt['city_to_coord'].values.copy()\n",
    "\n",
    "df_alt['city_from_name'] = c1\n",
    "df_alt['city_to_name'] = c2\n",
    "df_alt['city_from_coord'] = c3\n",
    "df_alt['city_to_coord'] = c4\n",
    "\n",
    "df_dists = pd.concat([df_dists, df_alt]).reset_index().drop(columns=['index'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.merge(df_ordersXproducts, df_dists, how='left', left_on=['origin_port', 'logistic_hub'], right_on=['city_from_name', 'city_to_name'])\n",
    "del df['city_from_name']\n",
    "del df['city_to_name']\n",
    "del df['city_from_coord']\n",
    "del df['city_to_coord']\n",
    "df = df.rename(columns={'distance': 'dist_origin_hub'})\n",
    "\n",
    "df = pd.merge(df, df_dists, how='left', left_on=['logistic_hub', 'customer'], right_on=['city_from_name', 'city_to_name'])\n",
    "del df['city_from_name']\n",
    "del df['city_to_name']\n",
    "del df['city_from_coord']\n",
    "del df['city_to_coord']\n",
    "df = df.rename(columns={'distance': 'dist_hub_customer'})\n",
    "\n",
    "df = pd.merge(df, df_dists, how='left', left_on=['origin_port', 'customer'], right_on=['city_from_name', 'city_to_name'])\n",
    "del df['city_from_name']\n",
    "del df['city_to_name']\n",
    "del df['city_from_coord']\n",
    "del df['city_to_coord']\n",
    "df = df.rename(columns={'distance': 'dist_origin_customer'})\n",
    "\n",
    "df = pd.merge(df, df_coord, how='left', left_on=['origin_port'], right_on=['city_from_name'])\n",
    "del df['city_from_name']\n",
    "df = df.rename(columns={'city_from_coord': 'origin_port_coord'})\n",
    "\n",
    "df = pd.merge(df, df_coord, how='left', left_on=['logistic_hub'], right_on=['city_from_name'])\n",
    "del df['city_from_name']\n",
    "df = df.rename(columns={'city_from_coord': 'logistic_hub_coord'})\n",
    "\n",
    "df = pd.merge(df, df_coord, how='left', left_on=['customer'], right_on=['city_from_name'])\n",
    "del df['city_from_name']\n",
    "df = df.rename(columns={'city_from_coord': 'customer_coord'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(df)):\n",
    "    if (not pd.isna(df.at[i, 'dist_origin_hub'])) and (not pd.isna(df.at[i, 'dist_hub_customer'])):\n",
    "        df.at[i, 'dist_origin_customer'] = df.at[i, 'dist_origin_hub'] + df.at[i, 'dist_hub_customer']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = df[~df['logistic_hub'].isna()]\n",
    "indexes = x[x['dist_hub_customer'].isna()].index\n",
    "\n",
    "for i in indexes:\n",
    "    df.at[i, 'dist_hub_customer'] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = df[df['dist_origin_customer'].isna()]\n",
    "indexes = x.index\n",
    "\n",
    "for i in indexes:\n",
    "    df.at[i, 'dist_origin_customer'] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = df[~df['logistic_hub'].isna()]\n",
    "indexes = x[x['dist_hub_customer'].isna()].index\n",
    "\n",
    "for i in indexes:\n",
    "    df.at[i, 'dist_hub_customer'] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = df[df['dist_origin_customer'].isna()]\n",
    "indexes = x.index\n",
    "\n",
    "for i in indexes:\n",
    "    df.at[i, 'dist_origin_customer'] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv('Datasets/finaldf.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import OneHotEncoder, StandardScaler\n",
    "from sklearn.compose import ColumnTransformer\n",
    "import torch\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import cross_validate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('Datasets/finaldf.csv')\n",
    "not_useful = ['order_id', 'origin_port_coord',\n",
    "       'logistic_hub_coord', 'customer_coord', 'logistic_hub', 'material_handling']\n",
    "for col in not_useful:\n",
    "    del df[col]\n",
    "df['weight'] = df['weight'].fillna(df['weight'].mean())\n",
    "df = df.dropna().reset_index().drop(columns=['index'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "units, weight = df['units'].values, df['weight'].values\n",
    "df['total_weight']= units*weight\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "categorical_columns = ['origin_port', '3pl', 'customs_procedures', 'product_id', 'customer']\n",
    "numerical_columns = ['units', 'weight', 'dist_origin_customer']\n",
    "\n",
    "target = df['late_order']\n",
    "data = df.drop(columns=['late_order'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "categorical_preprocessor = OneHotEncoder(handle_unknown=\"ignore\")\n",
    "numerical_preprocessor = StandardScaler()\n",
    "\n",
    "preprocessor = ColumnTransformer([\n",
    "    ('one-hot-encoder', categorical_preprocessor, categorical_columns),\n",
    "    ('standard_scaler', numerical_preprocessor, numerical_columns)])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jonathan/.local/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/jonathan/.local/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/jonathan/.local/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/jonathan/.local/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/jonathan/.local/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.8173580599161884"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = Pipeline(steps=[('preprocessor', preprocessor), \n",
    "                        ('classifier', LogisticRegression(max_iter=50))])\n",
    "cv_results = cross_validate(model, data, target, cv=5)\n",
    "cv_results['test_score'].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = np.squeeze(np.asarray(preprocessor.fit_transform(data).todense()))\n",
    "y = list(target.values)\n",
    "y = [[e] for e in y]\n",
    "y = torch.tensor(y, dtype=torch.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "padding = np.zeros(1024-len(x[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "z = []\n",
    "for i in range(len(x)):\n",
    "    z.append(list(np.concatenate((x[i], padding))))\n",
    "x = torch.tensor(z, dtype=torch.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jonathan/.local/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-2 {color: black;background-color: white;}#sk-container-id-2 pre{padding: 0;}#sk-container-id-2 div.sk-toggleable {background-color: white;}#sk-container-id-2 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-2 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-2 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-2 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-2 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-2 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-2 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-2 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-2 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-2 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-2 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-2 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-2 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-2 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-2 div.sk-item {position: relative;z-index: 1;}#sk-container-id-2 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-2 div.sk-item::before, #sk-container-id-2 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-2 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-2 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-2 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-2 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-2 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-2 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-2 div.sk-label-container {text-align: center;}#sk-container-id-2 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-2 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-2\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>Pipeline(steps=[(&#x27;preprocessor&#x27;,\n",
       "                 ColumnTransformer(transformers=[(&#x27;one-hot-encoder&#x27;,\n",
       "                                                  OneHotEncoder(handle_unknown=&#x27;ignore&#x27;),\n",
       "                                                  [&#x27;origin_port&#x27;, &#x27;3pl&#x27;,\n",
       "                                                   &#x27;customs_procedures&#x27;,\n",
       "                                                   &#x27;product_id&#x27;, &#x27;customer&#x27;]),\n",
       "                                                 (&#x27;standard_scaler&#x27;,\n",
       "                                                  StandardScaler(),\n",
       "                                                  [&#x27;units&#x27;, &#x27;weight&#x27;,\n",
       "                                                   &#x27;dist_origin_customer&#x27;])])),\n",
       "                (&#x27;classifier&#x27;, LogisticRegression(max_iter=50))])</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-8\" type=\"checkbox\" ><label for=\"sk-estimator-id-8\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">Pipeline</label><div class=\"sk-toggleable__content\"><pre>Pipeline(steps=[(&#x27;preprocessor&#x27;,\n",
       "                 ColumnTransformer(transformers=[(&#x27;one-hot-encoder&#x27;,\n",
       "                                                  OneHotEncoder(handle_unknown=&#x27;ignore&#x27;),\n",
       "                                                  [&#x27;origin_port&#x27;, &#x27;3pl&#x27;,\n",
       "                                                   &#x27;customs_procedures&#x27;,\n",
       "                                                   &#x27;product_id&#x27;, &#x27;customer&#x27;]),\n",
       "                                                 (&#x27;standard_scaler&#x27;,\n",
       "                                                  StandardScaler(),\n",
       "                                                  [&#x27;units&#x27;, &#x27;weight&#x27;,\n",
       "                                                   &#x27;dist_origin_customer&#x27;])])),\n",
       "                (&#x27;classifier&#x27;, LogisticRegression(max_iter=50))])</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-9\" type=\"checkbox\" ><label for=\"sk-estimator-id-9\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">preprocessor: ColumnTransformer</label><div class=\"sk-toggleable__content\"><pre>ColumnTransformer(transformers=[(&#x27;one-hot-encoder&#x27;,\n",
       "                                 OneHotEncoder(handle_unknown=&#x27;ignore&#x27;),\n",
       "                                 [&#x27;origin_port&#x27;, &#x27;3pl&#x27;, &#x27;customs_procedures&#x27;,\n",
       "                                  &#x27;product_id&#x27;, &#x27;customer&#x27;]),\n",
       "                                (&#x27;standard_scaler&#x27;, StandardScaler(),\n",
       "                                 [&#x27;units&#x27;, &#x27;weight&#x27;, &#x27;dist_origin_customer&#x27;])])</pre></div></div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-10\" type=\"checkbox\" ><label for=\"sk-estimator-id-10\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">one-hot-encoder</label><div class=\"sk-toggleable__content\"><pre>[&#x27;origin_port&#x27;, &#x27;3pl&#x27;, &#x27;customs_procedures&#x27;, &#x27;product_id&#x27;, &#x27;customer&#x27;]</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-11\" type=\"checkbox\" ><label for=\"sk-estimator-id-11\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">OneHotEncoder</label><div class=\"sk-toggleable__content\"><pre>OneHotEncoder(handle_unknown=&#x27;ignore&#x27;)</pre></div></div></div></div></div></div><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-12\" type=\"checkbox\" ><label for=\"sk-estimator-id-12\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">standard_scaler</label><div class=\"sk-toggleable__content\"><pre>[&#x27;units&#x27;, &#x27;weight&#x27;, &#x27;dist_origin_customer&#x27;]</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-13\" type=\"checkbox\" ><label for=\"sk-estimator-id-13\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">StandardScaler</label><div class=\"sk-toggleable__content\"><pre>StandardScaler()</pre></div></div></div></div></div></div></div></div><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-14\" type=\"checkbox\" ><label for=\"sk-estimator-id-14\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LogisticRegression</label><div class=\"sk-toggleable__content\"><pre>LogisticRegression(max_iter=50)</pre></div></div></div></div></div></div></div>"
      ],
      "text/plain": [
       "Pipeline(steps=[('preprocessor',\n",
       "                 ColumnTransformer(transformers=[('one-hot-encoder',\n",
       "                                                  OneHotEncoder(handle_unknown='ignore'),\n",
       "                                                  ['origin_port', '3pl',\n",
       "                                                   'customs_procedures',\n",
       "                                                   'product_id', 'customer']),\n",
       "                                                 ('standard_scaler',\n",
       "                                                  StandardScaler(),\n",
       "                                                  ['units', 'weight',\n",
       "                                                   'dist_origin_customer'])])),\n",
       "                ('classifier', LogisticRegression(max_iter=50))])"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(data, target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 2.32415549e-01, -1.29693332e-01, -6.08636427e-01,\n",
       "         6.08632474e-01, -6.58391621e-01, -2.23056801e-01,\n",
       "        -2.33098262e-01, -5.53974296e-01, -1.59687327e-01,\n",
       "         2.07747413e-01,  1.08783873e-01,  1.63058339e+00,\n",
       "        -7.94212962e-01, -5.83215901e-02, -4.14121251e-01,\n",
       "        -3.87875220e-01, -5.12304907e-02, -1.54013153e-01,\n",
       "        -4.93616710e-01, -6.25865384e-01, -8.68879661e-02,\n",
       "        -6.28197735e-01, -6.08472820e-01,  9.43374659e-02,\n",
       "        -2.72852712e-01, -3.82394992e-02,  5.35013571e-01,\n",
       "        -3.32640897e-01,  3.07378131e-01, -3.18222263e-01,\n",
       "        -2.60751053e-01, -7.80936792e-01, -2.17411438e-01,\n",
       "         2.26349989e+00, -8.25119807e-01, -2.79037193e-01,\n",
       "        -3.44961444e-01, -4.84245178e-01, -1.93218173e-01,\n",
       "        -4.40732341e-01, -3.32070504e-01, -9.93665528e-01,\n",
       "        -2.59940849e-01,  2.67739706e-01,  1.47224139e+00,\n",
       "        -8.98983961e-01, -1.95589054e-01, -6.84485959e-01,\n",
       "         1.66729285e+00,  2.02233161e+00, -2.38955081e-01,\n",
       "         1.34342623e-01, -4.78339164e-01, -7.06059816e-01,\n",
       "         1.76210002e+00, -6.08666414e-01, -7.98912932e-02,\n",
       "        -2.05073198e-01, -1.13355261e+00, -1.04034743e+00,\n",
       "        -6.69946533e-01, -6.25709269e-01, -6.03346482e-01,\n",
       "         5.42656907e-02, -4.26098759e-02, -1.91743047e-01,\n",
       "        -2.69118480e-01, -4.58921222e-02, -5.02552233e-01,\n",
       "        -4.97356810e-01, -9.93947649e-01, -2.30381825e-01,\n",
       "        -6.80598414e-01, -2.70252166e-01, -1.04844962e+00,\n",
       "        -5.98338006e-01, -6.01186379e-01, -5.70641356e-01,\n",
       "        -4.78317375e-03, -1.25067492e+00, -9.04442319e-01,\n",
       "        -6.76459025e-01, -7.13956457e-01, -1.16619123e+00,\n",
       "        -9.88759402e-02, -8.23831893e-01, -4.14340026e-01,\n",
       "         1.39042138e-02, -4.17991039e-01, -5.25926342e-01,\n",
       "        -8.15382109e-01, -2.01355167e-01, -2.23973541e-01,\n",
       "        -6.62369089e-01, -3.99519152e-01, -7.10736320e-01,\n",
       "         4.77414341e-02,  8.14109930e-03,  2.39072050e-01,\n",
       "         4.51562452e-01, -4.08307842e-02,  3.61398387e-01,\n",
       "         1.36168556e+00, -3.25472457e-01, -3.11046275e-01,\n",
       "         1.03913941e+00, -3.17745561e-01,  2.31579494e+00,\n",
       "        -6.11606046e-01,  1.63882588e-01, -4.59504763e-01,\n",
       "        -7.50258377e-01, -1.91063876e-01,  4.98214801e-01,\n",
       "        -9.52133893e-02,  1.16411731e+00,  4.78407598e-01,\n",
       "        -3.36816308e-01, -2.18731538e-01, -4.73706205e-01,\n",
       "        -5.99201539e-01, -6.41036772e-01, -9.95246329e-01,\n",
       "         1.34872884e+00, -1.62106063e-01, -4.39608582e-02,\n",
       "         3.78296812e-01, -6.49925560e-01, -6.18882272e-01,\n",
       "         6.47128141e-02, -4.83383130e-01, -3.67315258e-01,\n",
       "        -5.32151505e-01,  6.68990824e-01,  1.08743725e+00,\n",
       "         2.65898525e-01, -9.20675724e-01, -4.72940970e-01,\n",
       "         2.53461498e-01, -4.81660967e-02, -7.08935489e-01,\n",
       "        -3.74185282e-01, -2.03684557e-02,  1.66070231e+00,\n",
       "         2.69396730e-01,  1.37218186e-01,  9.51514911e-01,\n",
       "        -6.04691039e-01, -5.35163640e-01,  2.25496980e-02,\n",
       "        -9.91629358e-01,  1.15807111e+00,  1.07626788e-01,\n",
       "        -1.61453477e-01,  1.58868019e+00,  9.75739565e-01,\n",
       "        -4.27078748e-01,  8.86843885e-02,  9.07171666e-01,\n",
       "         1.46648556e+00, -3.20079632e-01,  4.82416546e-01,\n",
       "        -1.61239986e-01, -7.24852415e-01,  2.67350627e-01,\n",
       "         1.03165106e+00, -1.93621426e-01, -6.05854039e-01,\n",
       "         6.10589247e-01, -6.43657545e-01,  1.59923004e+00,\n",
       "        -2.37967563e-01, -7.80336580e-01, -2.01884199e-01,\n",
       "         3.77549738e-01, -3.48592018e-01, -6.27455521e-01,\n",
       "        -2.71352574e-01,  3.60304979e-01,  1.26561407e+00,\n",
       "        -4.21498705e-01,  1.74475149e+00, -8.67673699e-01,\n",
       "        -3.01792151e-01,  6.28380962e-01, -3.40599948e-01,\n",
       "        -7.87057700e-01, -8.02062098e-01,  2.06218230e+00,\n",
       "         8.01463375e-01, -4.33302741e-01,  9.22731959e-01,\n",
       "        -1.63005846e-01, -8.29541694e-01,  6.37112546e-01,\n",
       "         2.16270825e-01, -4.82341877e-01,  2.28025965e+00,\n",
       "        -6.66425168e-01, -4.46101491e-01, -5.43041404e-01,\n",
       "        -9.22641907e-01, -7.31700320e-01, -6.00893876e-01,\n",
       "        -3.31383191e-02, -3.78682430e-01,  1.70271724e+00,\n",
       "        -1.04325100e+00,  1.09294751e+00, -7.73312554e-01,\n",
       "        -2.54821034e-01, -1.01349795e-01, -9.48553052e-01,\n",
       "         2.62524055e+00, -3.38466532e-01,  2.54344785e+00,\n",
       "        -4.26780558e-01,  4.58480380e-02, -5.41978494e-01,\n",
       "        -5.54460351e-01,  1.09576765e+00, -9.11541853e-01,\n",
       "        -5.55592058e-01, -1.01386312e-01, -2.04238080e-01,\n",
       "        -4.94819976e-01,  2.21681225e+00, -8.99305486e-01,\n",
       "        -8.43171460e-01,  2.03879687e-02,  1.28149736e+00,\n",
       "        -7.01140660e-01,  1.00049796e-01,  3.42529484e-01,\n",
       "         5.06990901e-02, -5.33321714e-01,  4.14525387e-01,\n",
       "         2.47401115e+00, -6.71774084e-01, -9.98456488e-01,\n",
       "        -8.59086120e-01, -1.15724525e-01,  1.90116944e-02,\n",
       "         1.50519088e-01, -3.00027188e-01,  3.82257969e-01,\n",
       "         4.12924376e-01, -4.57708790e-01, -9.85301424e-01,\n",
       "        -6.06576574e-01, -8.38027601e-02, -8.63669949e-01,\n",
       "         1.00271387e+00, -3.26960931e-01, -6.36227192e-01,\n",
       "        -1.96925157e-01, -8.62842873e-01,  1.06348162e-01,\n",
       "        -3.18444420e-01,  4.39269057e-01, -3.47417956e-01,\n",
       "        -3.05330027e-01,  1.61584587e+00,  1.39693105e-01,\n",
       "         6.29170043e-01,  4.03827402e-01, -1.50695496e-01,\n",
       "        -3.93844206e-01,  1.37265714e+00, -5.37891953e-01,\n",
       "         4.18974642e-01, -3.27419042e-01, -7.66004860e-02,\n",
       "         1.27685842e-01, -1.21543581e-01, -3.40142118e-01,\n",
       "        -4.32452130e-01, -5.54863067e-01,  2.04608131e+00,\n",
       "        -7.23767107e-01, -4.84684336e-01, -6.22775238e-01,\n",
       "        -1.36092376e-01,  9.91206757e-01, -5.31333043e-01,\n",
       "         7.50246545e-01,  1.44570661e+00, -3.72140841e-01,\n",
       "        -6.82789813e-01,  1.38439068e+00,  3.98880956e-01,\n",
       "        -1.03423232e+00,  4.10160277e-03,  5.08560348e-01,\n",
       "        -5.44125281e-01, -7.07928790e-01, -1.71883254e-02,\n",
       "        -5.96499771e-01, -7.69883793e-01, -8.12639203e-01,\n",
       "        -8.95157134e-01,  2.11534892e-02,  1.23479371e+00,\n",
       "         5.47866386e-01,  1.26748084e-01,  2.71152290e-01,\n",
       "        -4.26003288e-02,  1.57463808e-02, -5.77861687e-01,\n",
       "        -1.00197246e-02, -8.71840374e-01, -2.60071600e-01,\n",
       "         1.80709878e-01,  1.28291197e+00, -1.76733660e-01,\n",
       "        -2.16705222e-01, -9.38663884e-01, -3.48722077e-01,\n",
       "         7.74395481e-01, -5.72492281e-01, -1.44419490e-01,\n",
       "         2.08766863e-02,  1.98226918e+00, -4.45844640e-01,\n",
       "        -4.87487762e-01, -5.16222778e-01, -5.28614778e-01,\n",
       "         6.56206450e-01,  4.20860773e+00, -1.22010279e-01,\n",
       "        -6.82346941e-01, -7.99571855e-01, -2.94236882e-01,\n",
       "        -5.27980638e-01,  1.15204176e+00, -9.26045689e-01,\n",
       "        -4.86603175e-01, -4.99517578e-01, -7.63944413e-01,\n",
       "         1.55293057e-01,  3.85193804e-01,  1.69013291e+00,\n",
       "        -5.27058673e-01, -5.82980948e-01,  2.83080961e-01,\n",
       "         3.57764451e-01,  1.20054339e-01,  4.76084669e-01,\n",
       "        -2.69866484e-01, -1.16160223e-01,  3.13568532e-01,\n",
       "        -1.89993736e-01, -3.92198341e-02, -1.52318913e-01,\n",
       "        -8.30978477e-01, -1.27662722e-01,  9.89542009e-01,\n",
       "        -5.42765720e-01,  7.91118880e-02, -2.85174322e-01,\n",
       "         2.43176303e+00,  2.16862660e+00,  1.65195581e+00,\n",
       "        -6.82381767e-01, -7.24748839e-01,  3.43477687e-01,\n",
       "        -1.94276092e-02,  1.20558685e-01,  3.62436231e-01,\n",
       "        -5.64313258e-01, -5.90554198e-01,  8.11184883e-01,\n",
       "        -7.42835352e-01,  9.40277014e-01, -8.41819381e-02,\n",
       "        -7.85273512e-01,  9.31841027e-02, -6.55492479e-01,\n",
       "        -4.38723581e-01,  3.02036757e-01,  2.91293478e-01,\n",
       "         3.35560182e-03,  1.70800317e-01, -8.69819723e-01,\n",
       "        -5.39588668e-01,  1.17850851e+00, -5.37498993e-01,\n",
       "        -3.00997678e-01, -2.35154073e-01,  4.39863556e-02,\n",
       "        -2.79251275e-01, -4.27836081e-01, -9.69326036e-02,\n",
       "        -5.30367994e-01,  2.10657560e-01,  8.14913701e-01,\n",
       "         8.47064847e-01, -4.15281816e-01, -8.12864041e-01,\n",
       "        -1.21263798e+00, -3.03815021e-01,  9.74306832e-01,\n",
       "         3.38897563e-01, -5.71227105e-01, -1.15522394e-01,\n",
       "        -1.13708260e-01, -6.05913019e-01, -3.28831681e-03,\n",
       "        -1.54182594e-02, -7.18691048e-01, -4.37241291e-01,\n",
       "         2.07393156e+00, -6.43038157e-01,  1.63764789e+00,\n",
       "        -8.24321120e-01, -4.22129082e-02,  3.44678329e+00,\n",
       "        -4.33272656e-01, -7.30396445e-01,  3.80113019e-01,\n",
       "         7.39367483e-01,  2.04029638e-01,  5.96371527e-01,\n",
       "        -7.17729998e-01, -3.84387718e-01, -6.06033150e-01,\n",
       "        -3.53011759e-01,  8.07292061e-01, -3.00486171e-01,\n",
       "        -1.99495646e-01, -5.72675568e-01,  1.08869051e+00,\n",
       "         9.24851631e-01, -5.04978088e-01,  1.08535221e-01,\n",
       "        -5.97898448e-01, -2.55458564e-01, -3.27621096e-01,\n",
       "        -1.37128843e-01, -1.15961755e-01, -8.96457000e-01,\n",
       "        -6.31392249e-01,  1.57910378e+00,  1.78138737e+00,\n",
       "        -3.43247954e-01,  2.09548511e+00, -1.91805523e-01,\n",
       "        -3.82607375e-01, -7.53932357e-01, -3.18095987e-01,\n",
       "        -1.10883927e-01,  1.59535163e-01, -7.13227958e-01,\n",
       "        -3.58994258e-01,  3.62328101e-01,  3.44838550e-01,\n",
       "         3.41411322e-01, -2.62686526e-01, -6.82782106e-01,\n",
       "         5.69781219e-01, -1.83502796e-01, -5.80040278e-01,\n",
       "        -1.72838214e-01, -5.26612072e-01, -1.42080625e-01,\n",
       "         2.78479799e-01, -7.26252592e-01, -4.62086257e-01,\n",
       "        -2.82336990e-01, -6.35209075e-02,  8.24500166e-03,\n",
       "        -7.47423650e-01, -6.60282988e-01, -3.43691146e-01,\n",
       "        -2.42470601e-01,  1.15384548e-01, -3.62591887e-01,\n",
       "        -1.87867862e-01, -7.38712952e-01, -2.50470441e-01,\n",
       "         1.53767377e-02,  7.72111744e-01, -7.75523359e-01,\n",
       "        -2.54198233e-02,  3.55576194e-01, -5.40172297e-01,\n",
       "        -2.72232031e-01,  1.31960132e+00, -3.90888458e-01,\n",
       "         5.03445476e-02, -6.08601320e-02,  7.55278882e-01,\n",
       "        -1.39425049e-01,  1.44509914e-01, -2.17637874e-03,\n",
       "        -5.47508215e-01, -4.60655435e-02, -1.63088523e-01,\n",
       "        -2.82248675e-03, -2.61419258e-01, -4.65247272e-01,\n",
       "         6.85673340e-01, -1.04640429e+00,  4.67786016e-01,\n",
       "        -6.95140085e-01, -1.30923190e-01,  1.78598319e-01,\n",
       "        -4.22339050e-01,  1.62750938e+00, -3.11153385e-01,\n",
       "        -3.46952595e-01,  1.15226641e+00,  3.10536005e-01,\n",
       "         1.26093005e+00,  1.01068141e+00, -1.45397424e-01,\n",
       "         2.43729079e-01, -5.76618826e-01,  1.01602854e-01,\n",
       "        -4.97308484e-01, -2.10499168e-01,  2.77550319e-01,\n",
       "        -2.93356142e-01,  1.25555165e+00, -9.36155455e-01,\n",
       "         4.41164606e-01, -7.97982034e-01, -3.83860892e-01,\n",
       "        -1.96522157e-01, -7.63913030e-01,  2.99139154e-01,\n",
       "        -2.05639543e-01, -3.38103937e-02, -2.69403106e-01,\n",
       "        -5.66097187e-01,  2.35017337e+00, -8.30966485e-01,\n",
       "        -8.18514010e-01,  2.53401879e+00, -8.72132127e-01,\n",
       "        -9.24291802e-01, -6.96227722e-01, -5.86650281e-01,\n",
       "        -6.24432698e-01, -9.22229002e-01,  1.47335421e+00,\n",
       "         1.78805294e-01,  5.55607131e-01, -5.40013841e-01,\n",
       "         1.86136246e+00, -1.52418760e-01, -2.38657718e-02,\n",
       "         2.06669610e-01, -1.24256725e-01,  8.06939540e-04,\n",
       "        -9.50549233e-02, -2.86450582e-02, -1.02450581e-01,\n",
       "        -9.78449816e-02,  2.53601438e-01,  5.08585634e-01,\n",
       "        -8.25838236e-01, -1.31384981e-02, -2.97569802e-01,\n",
       "         3.26438090e-01,  2.76125578e+00, -5.54745609e-01,\n",
       "         7.45594220e-01,  7.51974944e-02,  3.00533626e-01,\n",
       "        -7.51682263e-01, -2.86442465e-02,  9.61107373e-01,\n",
       "        -7.14829821e-01, -5.25153313e-02,  8.45889654e-01,\n",
       "        -3.52901353e-01, -8.14947686e-01, -9.41733749e-02,\n",
       "         4.28795044e-02, -8.23796020e-01, -1.11371562e+00,\n",
       "        -5.16730627e-01,  3.67223422e-02, -1.79444552e-01,\n",
       "         4.87927006e-01,  1.58861076e+00, -5.76675332e-01,\n",
       "        -2.33012557e-01, -2.52341743e-01,  2.07881567e-01,\n",
       "         1.20670638e+00,  8.85844110e-01, -1.51950312e-01,\n",
       "         1.71919783e+00, -4.58385998e-02, -4.41593990e-02,\n",
       "         3.11639679e-01,  5.23234811e-01, -6.29813218e-01,\n",
       "        -6.00930656e-01,  7.64214417e-01,  2.30193932e+00,\n",
       "        -5.78607966e-02, -1.63426529e-02, -2.31568976e-01,\n",
       "         1.93930718e-01, -2.61417472e-01, -5.18190505e-01,\n",
       "        -9.62158649e-01, -6.04637259e-01,  9.21876571e-02,\n",
       "        -6.48685286e-01, -6.54963294e-01, -2.89652825e-02,\n",
       "        -6.54170904e-01,  2.05540258e+00,  9.45363874e-01,\n",
       "        -5.97393209e-01, -3.21312007e-01, -9.67673857e-02,\n",
       "         3.69747563e-02, -4.27058068e-01,  3.64501936e-01,\n",
       "        -6.43379343e-02, -4.36180072e-01,  3.98257268e-01,\n",
       "        -5.71714960e-01, -8.28394210e-01,  1.22211898e+00,\n",
       "        -5.07169494e-01, -1.84119426e-02, -5.77399020e-01,\n",
       "        -6.75803821e-01, -5.05714295e-02,  1.40930280e+00,\n",
       "        -4.02221788e-01, -3.67639367e-01, -2.51938108e-01,\n",
       "        -5.04108087e-01, -4.88773459e-01, -8.67149896e-02,\n",
       "        -1.17609032e+00,  5.89637066e-01,  5.72046244e-01,\n",
       "        -2.04158540e-01, -2.45247927e-02,  1.09023313e+00,\n",
       "         9.53036171e-01, -3.27607684e-01, -5.38636358e-01,\n",
       "        -1.38208659e-01,  5.89971209e-01, -4.53698425e-01,\n",
       "        -1.08572150e+00, -3.29492410e-01,  1.27218386e-01,\n",
       "         8.66880807e-01, -2.82487448e-01, -5.01718956e-01,\n",
       "         9.05743173e-01,  1.28890510e-01, -5.12505575e-01,\n",
       "        -7.78508442e-01, -6.77588235e-01, -3.77887850e-01,\n",
       "        -4.65768951e-02, -4.14130202e-01, -7.17518030e-01,\n",
       "        -4.21910465e-01, -5.62553171e-01,  9.38880629e-01,\n",
       "        -9.78857762e-01, -6.38908215e-01, -5.89191673e-01,\n",
       "        -4.28487982e-01, -9.16902654e-02, -1.17996947e-01,\n",
       "         1.24132994e+00,  5.88061468e-02, -2.72966343e-02,\n",
       "         1.45170551e+00, -2.90382848e-01,  1.23210428e-02,\n",
       "         9.21151028e-04, -2.34383386e-01,  3.69187064e-01,\n",
       "        -6.69459554e-02, -1.59493180e-01,  1.29775574e+00,\n",
       "        -5.29981824e-01, -4.46061054e-01, -1.00519208e-01,\n",
       "        -9.52384108e-01, -4.76534152e-01, -1.22513113e-01,\n",
       "        -4.68324300e-01,  1.36550913e+00,  4.91627453e-01,\n",
       "        -7.74011147e-02,  4.77463299e-04, -5.08102064e-01,\n",
       "         1.72562663e+00, -5.62052908e-01,  3.31590721e-01,\n",
       "         1.70796728e+00,  1.37958474e+00,  7.52077269e-01,\n",
       "         7.98646445e-01, -2.94378156e-01,  2.63724944e+00,\n",
       "        -4.60974733e-01,  6.08428294e-03, -9.38369821e-02,\n",
       "         1.22175594e+00, -5.21235658e-01,  1.61836620e+00,\n",
       "         8.14593272e-01, -1.11169420e+00, -3.10788652e-01,\n",
       "         2.09388295e-01,  2.28027961e+00,  1.02260658e-01,\n",
       "         6.95054256e-01, -6.31462164e-01,  1.50440919e-02,\n",
       "         6.86622212e-01, -4.18171783e-02,  8.53614254e-01,\n",
       "         1.35492220e+00, -1.61671991e-01,  3.89652265e-03,\n",
       "        -3.46005261e-01,  7.41664501e-02, -6.01116366e-01,\n",
       "         5.52438733e-01,  2.14229642e-01, -1.04843468e-02,\n",
       "        -4.87142009e-01,  1.96636738e-02,  3.29147211e-01,\n",
       "        -2.72086082e-01, -6.58732110e-01,  5.73118988e-01,\n",
       "        -4.11538290e-01, -3.72701854e-01, -5.98640028e-01,\n",
       "         9.86301865e-01, -2.84665124e-01,  1.00191545e+00,\n",
       "        -1.17345426e+00, -2.23503985e-01, -8.03202190e-01,\n",
       "         1.42673434e+00,  5.25599139e-01,  3.56184422e-01,\n",
       "        -4.40451609e-01,  2.58440737e+00, -1.74933082e-01,\n",
       "        -4.68970237e-01, -2.50625976e-01, -3.05496058e-01,\n",
       "        -1.08230624e+00, -4.64709080e-01,  1.24998874e+00,\n",
       "         1.89606378e-01, -5.62340824e-01,  4.88895256e-01,\n",
       "         2.01995693e+00, -4.06551147e-01, -3.75548510e-01,\n",
       "        -7.36666206e-01, -1.28898622e+00, -1.52209441e-01,\n",
       "        -4.81226278e-01, -6.22633684e-02,  7.15419650e-01,\n",
       "        -1.74805932e-01, -6.34450322e-01, -3.89739594e-01,\n",
       "        -1.61101082e-01, -2.59597005e-01, -2.07107086e-01,\n",
       "        -1.91726117e-01,  5.90152487e-01, -2.21837155e-01,\n",
       "        -3.32405984e-01, -2.14741579e-01, -2.33176892e-01,\n",
       "         2.51043405e-01, -2.26381135e-01,  2.65858960e-01,\n",
       "         1.07732407e-01,  5.61636753e-01, -2.78479428e-01,\n",
       "         2.99788491e-01,  6.02166098e-01, -1.78216393e-01,\n",
       "        -1.87446372e-01, -2.63290346e-01,  5.49646430e-01,\n",
       "         6.54045805e-02, -1.57212595e-01, -2.03897135e-01,\n",
       "         1.47185291e-01, -2.54864599e-01, -2.18823694e-01,\n",
       "        -1.56224518e-01,  4.92430008e-01,  2.09742140e-01,\n",
       "         4.02642624e-01]])"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model['classifier'].coef_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "LogisticRegressionProbs = model.predict_proba(df_test.drop(columns=not_useful+['late_order']))[:, 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.1243    , 0.14126935, 0.23928753, ..., 0.12044055, 0.38198951,\n",
       "       0.21665572])"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "LogisticRegressionProbs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_pred_LR = pd.DataFrame()\n",
    "df_pred_LR['order_id'] = df_test['order_id']\n",
    "df_pred_LR['late_order'] = LogisticRegressionProbs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_pred_LR.to_csv('Predictions/pred_LogisticRegression4.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Papi DL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d_model = len(x[0])\n",
    "\n",
    "class Net(nn.Module):\n",
    "    \"\"\"\n",
    "    Text classifier based on a pytorch TransformerEncoder.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(\n",
    "        self,\n",
    "        nhead=4,\n",
    "        dim_feedforward=1024,\n",
    "        num_layers=4,\n",
    "        dropout=0.1,\n",
    "        activation=\"relu\",\n",
    "        classifier_dropout=0.1,\n",
    "    ):\n",
    "\n",
    "        super().__init__()\n",
    "\n",
    "        encoder_layer = nn.TransformerEncoderLayer(\n",
    "            d_model=d_model,\n",
    "            nhead=nhead,\n",
    "            dim_feedforward=dim_feedforward,\n",
    "            dropout=dropout,\n",
    "            batch_first=True\n",
    "        )\n",
    "        self.transformer_encoder = nn.TransformerEncoder(\n",
    "            encoder_layer,\n",
    "            num_layers=num_layers,\n",
    "        )\n",
    "        self.classifier = nn.Linear(d_model, 1)\n",
    "        self.d_model = d_model\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.transformer_encoder(x)\n",
    "        x = torch.sigmoid(self.classifier(x))\n",
    "\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'x_train' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-117-488890a65da2>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0mepoch_correct\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0mepoch_count\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 5\u001b[1;33m \u001b[0mpredictions\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx_train\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mbatch\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0mbatch_size\u001b[0m \u001b[1;33m:\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[1;33m+\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      6\u001b[0m \u001b[0mlabels\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0my_train\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mbatch\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0mbatch_size\u001b[0m \u001b[1;33m:\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[1;33m+\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'x_train' is not defined"
     ]
    }
   ],
   "source": [
    "batch = 0\n",
    "epoch_loss = 0\n",
    "epoch_correct = 0\n",
    "epoch_count = 0\n",
    "predictions = model(x_train[batch*batch_size : (batch+1)*batch_size].to(device))\n",
    "labels = y_train[batch*batch_size : (batch+1)*batch_size].to(device)\n",
    "\n",
    "loss = criterion(predictions, labels)\n",
    "\n",
    "correct = predictions.round() == labels\n",
    "acc = correct.sum().item() / correct.size(0)\n",
    "\n",
    "epoch_correct += correct.sum().item()\n",
    "epoch_count += correct.size(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9052734375"
      ]
     },
     "execution_count": 357,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "epoch_correct / epoch_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "starting\n",
      "epoch=0\n",
      "epoch_loss=51.87281847000122\n",
      "epoch accuracy: 0.7938537163267291\n",
      "epoch=1\n",
      "epoch_loss=45.233750373125076\n",
      "epoch accuracy: 0.8235153701296979\n",
      "epoch=2\n",
      "epoch_loss=44.430546551942825\n",
      "epoch accuracy: 0.8265036380836185\n",
      "epoch=3\n",
      "epoch_loss=43.90933087468147\n",
      "epoch accuracy: 0.828775782652132\n"
     ]
    }
   ],
   "source": [
    "epochs = 4\n",
    "model = Net().to(device)\n",
    "\n",
    "criterion = nn.BCELoss()\n",
    "\n",
    "lr = 1e-4\n",
    "optimizer = torch.optim.Adam(\n",
    "    (p for p in model.parameters() if p.requires_grad), lr=lr\n",
    ")\n",
    "\n",
    "torch.manual_seed(0)\n",
    "\n",
    "batch_size=1024\n",
    "batches = math.ceil(len(x)/batch_size)\n",
    "\n",
    "print(\"starting\")\n",
    "for epoch in range(epochs):\n",
    "    print(f\"{epoch=}\")\n",
    "    epoch_loss = 0\n",
    "    epoch_correct = 0\n",
    "    epoch_count = 0\n",
    "    for batch in range(math.ceil(len(x)/batch_size)):\n",
    "        optimizer.zero_grad()\n",
    "        predictions = model(x[batch*batch_size : (batch+1)*batch_size].to(device))\n",
    "        labels = y[batch*batch_size : (batch+1)*batch_size].to(device)\n",
    "\n",
    "        loss = criterion(predictions, labels)\n",
    "\n",
    "        correct = predictions.round() == labels\n",
    "        acc = correct.sum().item() / correct.size(0)\n",
    "\n",
    "        epoch_correct += correct.sum().item()\n",
    "        epoch_count += correct.size(0)\n",
    "\n",
    "        epoch_loss += loss.item()\n",
    "\n",
    "        loss.backward()\n",
    "\n",
    "        optimizer.step()\n",
    "    \"\"\"\n",
    "        predictions = model(x_train[batch*batch_size : (batch+1)*batch_size].to(device))\n",
    "        labels = y_train[batch*batch_size : (batch+1)*batch_size].to(device)\n",
    "\n",
    "        loss = criterion(predictions, labels)\n",
    "\n",
    "        correct = predictions.round() == labels\n",
    "        acc = correct.sum().item() / correct.size(0)\n",
    "\n",
    "        epoch_correct += correct.sum().item()\n",
    "        epoch_count += correct.size(0)\n",
    "\n",
    "        epoch_loss += loss.item()\n",
    "\n",
    "        loss.backward()\n",
    "\n",
    "        optimizer.step()\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        test_epoch_loss = 0\n",
    "        test_epoch_correct = 0\n",
    "        test_epoch_count = 0\n",
    "\n",
    "        for batch in range(math.ceil(len(x_test)/batch_size)):\n",
    "            predictions = model(x_test[batch*batch_size : (batch+1)*batch_size].to(device))\n",
    "            labels = y_test[batch*batch_size : (batch+1)*batch_size].to(device)\n",
    "            test_loss = criterion(predictions, labels)\n",
    "\n",
    "            correct = predictions.round() == labels\n",
    "            acc = correct.sum().item() / correct.size(0)\n",
    "\n",
    "            test_epoch_correct += correct.sum().item()\n",
    "            test_epoch_count += correct.size(0)\n",
    "            test_epoch_loss += loss.item()\n",
    "\n",
    "    print(f\"{epoch_loss=}\")\n",
    "    print(f\"epoch accuracy: {epoch_correct / epoch_count}\")\n",
    "    print(f\"{test_epoch_loss=}\")\n",
    "    print(f\"test epoch accuracy: {test_epoch_correct / test_epoch_count}\")\n",
    "    \"\"\"\n",
    "    print(f\"{epoch_loss=}\")\n",
    "    print(f\"epoch accuracy: {epoch_correct / epoch_count}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model.state_dict(), 'DLmodel/PapiDL.model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "data = df_test.drop(columns=not_useful+['late_order'])\n",
    "\n",
    "k = np.squeeze(np.asarray(preprocessor.fit_transform(data).todense()))\n",
    "\n",
    "padding = np.zeros(1024-len(k[0]))\n",
    "\n",
    "z = []\n",
    "for i in range(len(k)):\n",
    "    z.append(list(np.concatenate((k[i], padding))))\n",
    "k = torch.tensor(z, dtype=torch.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds = []\n",
    "batch_size=128\n",
    "for batch in range(math.ceil(len(k)/batch_size)):\n",
    "    preds.append(model(k[batch*batch_size : (batch+1)*batch_size].to(device)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds = torch.cat(list(torch.cat(preds))).detach().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def trans(num):\n",
    "    return 1 - num\n",
    "t = np.vectorize(trans)\n",
    "p = t(p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.25205749, 0.30069175, 0.09594342, ..., 0.16871293, 0.19298422,\n",
       "       0.08183663])"
      ]
     },
     "execution_count": 125,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_pred_DL = pd.DataFrame()\n",
    "df_pred_DL['order_id'] = df_test['order_id']\n",
    "df_pred_DL['late_order'] = p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_pred_DL.to_csv('Predictions/pred_DL.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.6 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "vscode": {
   "interpreter": {
    "hash": "916dbcbb3f70747c44a77c7bcd40155683ae19c65e1c03b4aa3499c5328201f1"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
