{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.004443,
     "end_time": "2022-11-11T08:46:48.019499",
     "exception": false,
     "start_time": "2022-11-11T08:46:48.015056",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Sarter Notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "papermill": {
     "duration": 1.688634,
     "end_time": "2022-11-11T08:46:49.712044",
     "exception": false,
     "start_time": "2022-11-11T08:46:48.02341",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import math\n",
    "import haversine as hs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.003519,
     "end_time": "2022-11-11T08:46:49.719635",
     "exception": false,
     "start_time": "2022-11-11T08:46:49.716116",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Reading Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {
    "papermill": {
     "duration": 0.383908,
     "end_time": "2022-11-11T08:46:50.10727",
     "exception": false,
     "start_time": "2022-11-11T08:46:49.723362",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# read train data\n",
    "df_orders = pd.read_csv(\"orders.csv\", sep=\";\")\n",
    "df_products = pd.read_csv(\"product_attributes.csv\", sep=\",\")\n",
    "df_dists = pd.read_csv(\"cities_data.csv\", sep=\";\")\n",
    "df_ordersXproducts = pd.read_csv('ordersXproducts.csv')\n",
    "del df_ordersXproducts['Unnamed: 0']\n",
    "\n",
    "# read test data\n",
    "df_test = pd.read_csv('finaltest.csv')\n",
    "df_test['weight'] = df_test['weight'].fillna(df_test['weight'].mean())\n",
    "df_test['late_order'] = True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Merge tables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_coord = df_dists[['city_from_name', 'city_from_coord']].drop_duplicates().reset_index().drop(columns=['index']).copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_alt = df_dists.copy()\n",
    "\n",
    "c2 = df_alt['city_from_name'].values.copy()\n",
    "c1 = df_alt['city_to_name'].values.copy()\n",
    "c4 = df_alt['city_from_coord'].values.copy()\n",
    "c3 = df_alt['city_to_coord'].values.copy()\n",
    "\n",
    "df_alt['city_from_name'] = c1\n",
    "df_alt['city_to_name'] = c2\n",
    "df_alt['city_from_coord'] = c3\n",
    "df_alt['city_to_coord'] = c4\n",
    "\n",
    "df_dists = pd.concat([df_dists, df_alt]).reset_index().drop(columns=['index'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.merge(df_ordersXproducts, df_dists, how='left', left_on=['origin_port', 'logistic_hub'], right_on=['city_from_name', 'city_to_name'])\n",
    "del df['city_from_name']\n",
    "del df['city_to_name']\n",
    "del df['city_from_coord']\n",
    "del df['city_to_coord']\n",
    "df = df.rename(columns={'distance': 'dist_origin_hub'})\n",
    "\n",
    "df = pd.merge(df, df_dists, how='left', left_on=['logistic_hub', 'customer'], right_on=['city_from_name', 'city_to_name'])\n",
    "del df['city_from_name']\n",
    "del df['city_to_name']\n",
    "del df['city_from_coord']\n",
    "del df['city_to_coord']\n",
    "df = df.rename(columns={'distance': 'dist_hub_customer'})\n",
    "\n",
    "df = pd.merge(df, df_dists, how='left', left_on=['origin_port', 'customer'], right_on=['city_from_name', 'city_to_name'])\n",
    "del df['city_from_name']\n",
    "del df['city_to_name']\n",
    "del df['city_from_coord']\n",
    "del df['city_to_coord']\n",
    "df = df.rename(columns={'distance': 'dist_origin_customer'})\n",
    "\n",
    "df = pd.merge(df, df_coord, how='left', left_on=['origin_port'], right_on=['city_from_name'])\n",
    "del df['city_from_name']\n",
    "df = df.rename(columns={'city_from_coord': 'origin_port_coord'})\n",
    "\n",
    "df = pd.merge(df, df_coord, how='left', left_on=['logistic_hub'], right_on=['city_from_name'])\n",
    "del df['city_from_name']\n",
    "df = df.rename(columns={'city_from_coord': 'logistic_hub_coord'})\n",
    "\n",
    "df = pd.merge(df, df_coord, how='left', left_on=['customer'], right_on=['city_from_name'])\n",
    "del df['city_from_name']\n",
    "df = df.rename(columns={'city_from_coord': 'customer_coord'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(df)):\n",
    "    if (not pd.isna(df.at[i, 'dist_origin_hub'])) and (not pd.isna(df.at[i, 'dist_hub_customer'])):\n",
    "        df.at[i, 'dist_origin_customer'] = df.at[i, 'dist_origin_hub'] + df.at[i, 'dist_hub_customer']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "order_id                   0\n",
       "origin_port                0\n",
       "3pl                        0\n",
       "customs_procedures         0\n",
       "logistic_hub            1049\n",
       "customer                   0\n",
       "product_id                 0\n",
       "units                      0\n",
       "late_order                 0\n",
       "weight                   118\n",
       "material_handling        118\n",
       "dist_origin_hub         1049\n",
       "dist_hub_customer       1049\n",
       "dist_origin_customer       0\n",
       "origin_port_coord          0\n",
       "logistic_hub_coord      1049\n",
       "customer_coord          1112\n",
       "dtype: int64"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = df[~df['logistic_hub'].isna()]\n",
    "indexes = x[x['dist_hub_customer'].isna()].index\n",
    "\n",
    "for i in indexes:\n",
    "    df.at[i, 'dist_hub_customer'] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = df[df['dist_origin_customer'].isna()]\n",
    "indexes = x.index\n",
    "\n",
    "for i in indexes:\n",
    "    df.at[i, 'dist_origin_customer'] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>order_id</th>\n",
       "      <th>origin_port</th>\n",
       "      <th>3pl</th>\n",
       "      <th>customs_procedures</th>\n",
       "      <th>logistic_hub</th>\n",
       "      <th>customer</th>\n",
       "      <th>product_id</th>\n",
       "      <th>units</th>\n",
       "      <th>late_order</th>\n",
       "      <th>weight</th>\n",
       "      <th>material_handling</th>\n",
       "      <th>dist_origin_hub</th>\n",
       "      <th>dist_hub_customer</th>\n",
       "      <th>dist_origin_customer</th>\n",
       "      <th>origin_port_coord</th>\n",
       "      <th>logistic_hub_coord</th>\n",
       "      <th>customer_coord</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>366c7a3d298f</td>\n",
       "      <td>Rotterdam</td>\n",
       "      <td>v_002</td>\n",
       "      <td>DTP</td>\n",
       "      <td>Venlo</td>\n",
       "      <td>Marseille</td>\n",
       "      <td>1692723</td>\n",
       "      <td>583</td>\n",
       "      <td>1</td>\n",
       "      <td>1778.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>130.0459</td>\n",
       "      <td>902.0420</td>\n",
       "      <td>1032.0879</td>\n",
       "      <td>(51.9244424, 4.47775)</td>\n",
       "      <td>(51.39244885, 6.1511724144122955)</td>\n",
       "      <td>(43.2961743, 5.3699525)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>45f906331e10</td>\n",
       "      <td>Rotterdam</td>\n",
       "      <td>v_004</td>\n",
       "      <td>CRF</td>\n",
       "      <td>Rome</td>\n",
       "      <td>Marseille</td>\n",
       "      <td>1644308</td>\n",
       "      <td>459</td>\n",
       "      <td>0</td>\n",
       "      <td>1088.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1269.2365</td>\n",
       "      <td>604.0216</td>\n",
       "      <td>1873.2581</td>\n",
       "      <td>(51.9244424, 4.47775)</td>\n",
       "      <td>(41.8933203, 12.4829321)</td>\n",
       "      <td>(43.2961743, 5.3699525)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ac84a6e4af0f</td>\n",
       "      <td>Athens</td>\n",
       "      <td>v_002</td>\n",
       "      <td>CRF</td>\n",
       "      <td>Venlo</td>\n",
       "      <td>Paris</td>\n",
       "      <td>1684170</td>\n",
       "      <td>464</td>\n",
       "      <td>1</td>\n",
       "      <td>505.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2029.5726</td>\n",
       "      <td>392.9249</td>\n",
       "      <td>2422.4975</td>\n",
       "      <td>(37.9839412, 23.7283052)</td>\n",
       "      <td>(51.39244885, 6.1511724144122955)</td>\n",
       "      <td>(48.8588897, 2.3200410217200766)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>f5e98cb29790</td>\n",
       "      <td>Rotterdam</td>\n",
       "      <td>v_004</td>\n",
       "      <td>CRF</td>\n",
       "      <td>Lille</td>\n",
       "      <td>Milan</td>\n",
       "      <td>1620510</td>\n",
       "      <td>678</td>\n",
       "      <td>0</td>\n",
       "      <td>1308.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>173.9644</td>\n",
       "      <td>733.8784</td>\n",
       "      <td>907.8428</td>\n",
       "      <td>(51.9244424, 4.47775)</td>\n",
       "      <td>(50.6365654, 3.0635282)</td>\n",
       "      <td>(45.4641943, 9.1896346)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>a9e7c9bee35b</td>\n",
       "      <td>Barcelona</td>\n",
       "      <td>v_002</td>\n",
       "      <td>CRF</td>\n",
       "      <td>Venlo</td>\n",
       "      <td>Berlin</td>\n",
       "      <td>1699372</td>\n",
       "      <td>353</td>\n",
       "      <td>0</td>\n",
       "      <td>1465.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1153.4178</td>\n",
       "      <td>512.8188</td>\n",
       "      <td>1666.2366</td>\n",
       "      <td>(41.3828939, 2.1774322)</td>\n",
       "      <td>(51.39244885, 6.1511724144122955)</td>\n",
       "      <td>(52.5170365, 13.3888599)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>114271</th>\n",
       "      <td>3f4b15fb770e</td>\n",
       "      <td>Rotterdam</td>\n",
       "      <td>v_002</td>\n",
       "      <td>CRF</td>\n",
       "      <td>Dusseldorf</td>\n",
       "      <td>Bordeaux</td>\n",
       "      <td>1681376</td>\n",
       "      <td>645</td>\n",
       "      <td>0</td>\n",
       "      <td>1896.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>177.3075</td>\n",
       "      <td>896.2065</td>\n",
       "      <td>1073.5140</td>\n",
       "      <td>(51.9244424, 4.47775)</td>\n",
       "      <td>(51.2254018, 6.7763137)</td>\n",
       "      <td>(44.841225, -0.5800364)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>114272</th>\n",
       "      <td>d2e6978a38fd</td>\n",
       "      <td>Barcelona</td>\n",
       "      <td>v_004</td>\n",
       "      <td>DTD</td>\n",
       "      <td>Dusseldorf</td>\n",
       "      <td>Berlin</td>\n",
       "      <td>1676942</td>\n",
       "      <td>502</td>\n",
       "      <td>0</td>\n",
       "      <td>746.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1149.4065</td>\n",
       "      <td>477.3717</td>\n",
       "      <td>1626.7782</td>\n",
       "      <td>(41.3828939, 2.1774322)</td>\n",
       "      <td>(51.2254018, 6.7763137)</td>\n",
       "      <td>(52.5170365, 13.3888599)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>114273</th>\n",
       "      <td>b88babd5c7bd</td>\n",
       "      <td>Rotterdam</td>\n",
       "      <td>v_002</td>\n",
       "      <td>DTP</td>\n",
       "      <td>Dusseldorf</td>\n",
       "      <td>Rome</td>\n",
       "      <td>1692737</td>\n",
       "      <td>464</td>\n",
       "      <td>0</td>\n",
       "      <td>572.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>177.3075</td>\n",
       "      <td>1125.0290</td>\n",
       "      <td>1302.3365</td>\n",
       "      <td>(51.9244424, 4.47775)</td>\n",
       "      <td>(51.2254018, 6.7763137)</td>\n",
       "      <td>(41.8933203, 12.4829321)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>114274</th>\n",
       "      <td>b0b5c761613f</td>\n",
       "      <td>Barcelona</td>\n",
       "      <td>v_003</td>\n",
       "      <td>DTD</td>\n",
       "      <td>Dusseldorf</td>\n",
       "      <td>Munich</td>\n",
       "      <td>1699974</td>\n",
       "      <td>388</td>\n",
       "      <td>0</td>\n",
       "      <td>1894.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1149.4065</td>\n",
       "      <td>487.5926</td>\n",
       "      <td>1636.9991</td>\n",
       "      <td>(41.3828939, 2.1774322)</td>\n",
       "      <td>(51.2254018, 6.7763137)</td>\n",
       "      <td>(48.1371079, 11.5753822)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>114275</th>\n",
       "      <td>1ab8e51519e4</td>\n",
       "      <td>Rotterdam</td>\n",
       "      <td>v_002</td>\n",
       "      <td>DTD</td>\n",
       "      <td>Venlo</td>\n",
       "      <td>Bucharest</td>\n",
       "      <td>1620510</td>\n",
       "      <td>482</td>\n",
       "      <td>0</td>\n",
       "      <td>1308.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>130.0459</td>\n",
       "      <td>1672.4754</td>\n",
       "      <td>1802.5213</td>\n",
       "      <td>(51.9244424, 4.47775)</td>\n",
       "      <td>(51.39244885, 6.1511724144122955)</td>\n",
       "      <td>(44.4361414, 26.1027202)</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>114276 rows × 17 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            order_id origin_port    3pl customs_procedures logistic_hub  \\\n",
       "0       366c7a3d298f   Rotterdam  v_002                DTP        Venlo   \n",
       "1       45f906331e10   Rotterdam  v_004                CRF         Rome   \n",
       "2       ac84a6e4af0f      Athens  v_002                CRF        Venlo   \n",
       "3       f5e98cb29790   Rotterdam  v_004                CRF        Lille   \n",
       "4       a9e7c9bee35b   Barcelona  v_002                CRF        Venlo   \n",
       "...              ...         ...    ...                ...          ...   \n",
       "114271  3f4b15fb770e   Rotterdam  v_002                CRF   Dusseldorf   \n",
       "114272  d2e6978a38fd   Barcelona  v_004                DTD   Dusseldorf   \n",
       "114273  b88babd5c7bd   Rotterdam  v_002                DTP   Dusseldorf   \n",
       "114274  b0b5c761613f   Barcelona  v_003                DTD   Dusseldorf   \n",
       "114275  1ab8e51519e4   Rotterdam  v_002                DTD        Venlo   \n",
       "\n",
       "         customer  product_id  units  late_order  weight  material_handling  \\\n",
       "0       Marseille     1692723    583           1  1778.0                5.0   \n",
       "1       Marseille     1644308    459           0  1088.0                3.0   \n",
       "2           Paris     1684170    464           1   505.0                4.0   \n",
       "3           Milan     1620510    678           0  1308.0                4.0   \n",
       "4          Berlin     1699372    353           0  1465.0                0.0   \n",
       "...           ...         ...    ...         ...     ...                ...   \n",
       "114271   Bordeaux     1681376    645           0  1896.0                3.0   \n",
       "114272     Berlin     1676942    502           0   746.0                1.0   \n",
       "114273       Rome     1692737    464           0   572.0                5.0   \n",
       "114274     Munich     1699974    388           0  1894.0                1.0   \n",
       "114275  Bucharest     1620510    482           0  1308.0                4.0   \n",
       "\n",
       "        dist_origin_hub  dist_hub_customer  dist_origin_customer  \\\n",
       "0              130.0459           902.0420             1032.0879   \n",
       "1             1269.2365           604.0216             1873.2581   \n",
       "2             2029.5726           392.9249             2422.4975   \n",
       "3              173.9644           733.8784              907.8428   \n",
       "4             1153.4178           512.8188             1666.2366   \n",
       "...                 ...                ...                   ...   \n",
       "114271         177.3075           896.2065             1073.5140   \n",
       "114272        1149.4065           477.3717             1626.7782   \n",
       "114273         177.3075          1125.0290             1302.3365   \n",
       "114274        1149.4065           487.5926             1636.9991   \n",
       "114275         130.0459          1672.4754             1802.5213   \n",
       "\n",
       "               origin_port_coord                 logistic_hub_coord  \\\n",
       "0          (51.9244424, 4.47775)  (51.39244885, 6.1511724144122955)   \n",
       "1          (51.9244424, 4.47775)           (41.8933203, 12.4829321)   \n",
       "2       (37.9839412, 23.7283052)  (51.39244885, 6.1511724144122955)   \n",
       "3          (51.9244424, 4.47775)            (50.6365654, 3.0635282)   \n",
       "4        (41.3828939, 2.1774322)  (51.39244885, 6.1511724144122955)   \n",
       "...                          ...                                ...   \n",
       "114271     (51.9244424, 4.47775)            (51.2254018, 6.7763137)   \n",
       "114272   (41.3828939, 2.1774322)            (51.2254018, 6.7763137)   \n",
       "114273     (51.9244424, 4.47775)            (51.2254018, 6.7763137)   \n",
       "114274   (41.3828939, 2.1774322)            (51.2254018, 6.7763137)   \n",
       "114275     (51.9244424, 4.47775)  (51.39244885, 6.1511724144122955)   \n",
       "\n",
       "                          customer_coord  \n",
       "0                (43.2961743, 5.3699525)  \n",
       "1                (43.2961743, 5.3699525)  \n",
       "2       (48.8588897, 2.3200410217200766)  \n",
       "3                (45.4641943, 9.1896346)  \n",
       "4               (52.5170365, 13.3888599)  \n",
       "...                                  ...  \n",
       "114271           (44.841225, -0.5800364)  \n",
       "114272          (52.5170365, 13.3888599)  \n",
       "114273          (41.8933203, 12.4829321)  \n",
       "114274          (48.1371079, 11.5753822)  \n",
       "114275          (44.4361414, 26.1027202)  \n",
       "\n",
       "[114276 rows x 17 columns]"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv('finaldf.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = df[~df['logistic_hub'].isna()]\n",
    "indexes = x[x['dist_hub_customer'].isna()].index\n",
    "\n",
    "for i in indexes:\n",
    "    df.at[i, 'dist_hub_customer'] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = df[df['dist_origin_customer'].isna()]\n",
    "indexes = x.index\n",
    "\n",
    "for i in indexes:\n",
    "    df.at[i, 'dist_origin_customer'] = 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Merge test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test = df_test.replace('ATHENAS', 'Athens')\n",
    "df_test = df_test.replace('BCN', 'Barcelona')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.merge(df_test, df_products, how='left', left_on=['product_id'], right_on=['product_id'])\n",
    "\n",
    "df = pd.merge(df, df_dists, how='left', left_on=['origin_port', 'logistic_hub'], right_on=['city_from_name', 'city_to_name'])\n",
    "del df['city_from_name']\n",
    "del df['city_to_name']\n",
    "del df['city_from_coord']\n",
    "del df['city_to_coord']\n",
    "df = df.rename(columns={'distance': 'dist_origin_hub'})\n",
    "\n",
    "df = pd.merge(df, df_dists, how='left', left_on=['logistic_hub', 'customer'], right_on=['city_from_name', 'city_to_name'])\n",
    "del df['city_from_name']\n",
    "del df['city_to_name']\n",
    "del df['city_from_coord']\n",
    "del df['city_to_coord']\n",
    "df = df.rename(columns={'distance': 'dist_hub_customer'})\n",
    "\n",
    "df = pd.merge(df, df_dists, how='left', left_on=['origin_port', 'customer'], right_on=['city_from_name', 'city_to_name'])\n",
    "del df['city_from_name']\n",
    "del df['city_to_name']\n",
    "del df['city_from_coord']\n",
    "del df['city_to_coord']\n",
    "df = df.rename(columns={'distance': 'dist_origin_customer'})\n",
    "\n",
    "df = pd.merge(df, df_coord, how='left', left_on=['origin_port'], right_on=['city_from_name'])\n",
    "del df['city_from_name']\n",
    "df = df.rename(columns={'city_from_coord': 'origin_port_coord'})\n",
    "\n",
    "df = pd.merge(df, df_coord, how='left', left_on=['logistic_hub'], right_on=['city_from_name'])\n",
    "del df['city_from_name']\n",
    "df = df.rename(columns={'city_from_coord': 'logistic_hub_coord'})\n",
    "\n",
    "df = pd.merge(df, df_coord, how='left', left_on=['customer'], right_on=['city_from_name'])\n",
    "del df['city_from_name']\n",
    "df = df.rename(columns={'city_from_coord': 'customer_coord'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(df)):\n",
    "    if (not pd.isna(df.at[i, 'dist_origin_hub'])) and (not pd.isna(df.at[i, 'dist_hub_customer'])):\n",
    "        df.at[i, 'dist_origin_customer'] = df.at[i, 'dist_origin_hub'] + df.at[i, 'dist_hub_customer']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "order_id                  0\n",
       "origin_port               0\n",
       "3pl                       0\n",
       "customs_procedures        0\n",
       "logistic_hub            265\n",
       "customer                  0\n",
       "product_id                0\n",
       "units                     0\n",
       "weight                   45\n",
       "material_handling        45\n",
       "dist_origin_hub         265\n",
       "dist_hub_customer       265\n",
       "dist_origin_customer      0\n",
       "origin_port_coord         0\n",
       "logistic_hub_coord      265\n",
       "customer_coord          288\n",
       "dtype: int64"
      ]
     },
     "execution_count": 168,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = df[~df['logistic_hub'].isna()]\n",
    "indexes = x[x['dist_hub_customer'].isna()].index\n",
    "\n",
    "for i in indexes:\n",
    "    df.at[i, 'dist_hub_customer'] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = df[df['dist_origin_customer'].isna()]\n",
    "indexes = x.index\n",
    "\n",
    "for i in indexes:\n",
    "    df.at[i, 'dist_origin_customer'] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv('finaltest.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import OneHotEncoder, StandardScaler\n",
    "from category_encoders.binary import BinaryEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import cross_validate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('finaldf.csv')\n",
    "not_useful = ['order_id', 'origin_port_coord',\n",
    "       'logistic_hub_coord', 'customer_coord', 'logistic_hub', 'material_handling']\n",
    "for col in not_useful:\n",
    "    del df[col]\n",
    "df['weight'] = df['weight'].fillna(df['weight'].mean())\n",
    "df = df.dropna().reset_index().drop(columns=['index'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "metadata": {},
   "outputs": [],
   "source": [
    "units, weight = df['units'].values, df['weight'].values\n",
    "df['total_weight']= units*weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "metadata": {},
   "outputs": [],
   "source": [
    "categorical_columns = ['origin_port', '3pl', 'customs_procedures', 'product_id', 'customer']\n",
    "numerical_columns = ['total_weight', 'units', 'weight', 'dist_origin_customer']\n",
    "\n",
    "target = df['late_order']\n",
    "data = df.drop(columns=['late_order'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "metadata": {},
   "outputs": [],
   "source": [
    "categorical_preprocessor = OneHotEncoder(handle_unknown=\"ignore\")\n",
    "numerical_preprocessor = StandardScaler()\n",
    "\n",
    "preprocessor = ColumnTransformer([\n",
    "    ('one-hot-encoder', categorical_preprocessor, categorical_columns),\n",
    "    ('standard_scaler', numerical_preprocessor, numerical_columns)])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\thoma\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\thoma\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\thoma\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\thoma\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\thoma\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.8226748043319093"
      ]
     },
     "execution_count": 209,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = Pipeline(steps=[('preprocessor', preprocessor), \n",
    "                        ('classifier', LogisticRegression(max_iter=50))])\n",
    "cv_results = cross_validate(model, data, target, cv=5)\n",
    "cv_results['test_score'].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'LogisticRegression' object has no attribute 'coef_'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-210-2f79c2d1cdb6>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mmodel\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'classifier'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcoef_\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m: 'LogisticRegression' object has no attribute 'coef_'"
     ]
    }
   ],
   "source": [
    "model['classifier'].coef_[0][-2:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "808"
      ]
     },
     "execution_count": 189,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num = 0\n",
    "for col in categorical_columns:\n",
    "    num += len(df[col].unique())\n",
    "num"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "811"
      ]
     },
     "execution_count": 191,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(np.squeeze(np.asarray(preprocessor.fit_transform(data).todense()))[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.        ,  0.        ,  1.        ,  0.        ,  1.        ,\n",
       "        0.        ,  0.        ,  0.        ,  0.        ,  1.        ,\n",
       "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "        1.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "        0.        ,  1.        ,  0.        ,  0.        ,  0.        ,\n",
       "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "        0.        ,  0.        ,  0.        ,  1.43419069,  0.99586017,\n",
       "       -1.04179957])"
      ]
     },
     "execution_count": 173,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.squeeze(np.asarray(preprocessor.fit_transform(data).todense()))[0][-3:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = np.squeeze(np.asarray(preprocessor.fit_transform(data).todense()))\n",
    "y = list(target.values)\n",
    "y = [[e] for e in y]\n",
    "y = torch.tensor(y, dtype=torch.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [],
   "source": [
    "padding = np.zeros(1024-len(x[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [],
   "source": [
    "z = []\n",
    "for i in range(len(x)):\n",
    "    z.append(list(np.concatenate((x[i], padding))))\n",
    "x = torch.tensor(z, dtype=torch.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\thoma\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Pipeline(steps=[('preprocessor',\n",
       "                 ColumnTransformer(transformers=[('one-hot-encoder',\n",
       "                                                  OneHotEncoder(handle_unknown='ignore'),\n",
       "                                                  ['origin_port', '3pl',\n",
       "                                                   'customs_procedures',\n",
       "                                                   'product_id', 'customer']),\n",
       "                                                 ('standard_scaler',\n",
       "                                                  StandardScaler(),\n",
       "                                                  ['total_weight', 'units',\n",
       "                                                   'weight',\n",
       "                                                   'dist_origin_customer'])])),\n",
       "                ('classifier', LogisticRegression(max_iter=50))])"
      ]
     },
     "execution_count": 211,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(data, target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 2.37607329e-01, -1.43954377e-01, -6.07072455e-01,\n",
       "         5.47376384e-01, -6.45289311e-01, -2.14684190e-01,\n",
       "        -2.00822386e-01, -5.64129769e-01, -1.59045498e-01,\n",
       "         2.09755764e-01,  6.46201711e-02,  1.49131159e+00,\n",
       "        -7.18783915e-01, -5.42722081e-02, -3.89862955e-01,\n",
       "        -5.34291147e-01, -6.61715437e-02, -1.43272600e-01,\n",
       "        -3.96985974e-01, -9.85899120e-01, -9.07160345e-02,\n",
       "        -5.41839152e-01, -5.43056524e-01, -3.65868344e-02,\n",
       "        -2.99508363e-01, -1.53679624e-01,  5.09532298e-01,\n",
       "        -2.40987586e-01,  2.18171615e-01, -2.82120073e-01,\n",
       "        -2.11179885e-01, -7.57320118e-01, -3.50086282e-01,\n",
       "         2.02277737e+00, -7.49554693e-01, -2.37243611e-01,\n",
       "        -3.53444289e-01, -5.14359697e-01, -1.60350814e-01,\n",
       "        -3.53134356e-01, -2.74749578e-01, -9.41475641e-01,\n",
       "        -2.19171631e-01,  2.21995788e-01,  1.28205766e+00,\n",
       "        -7.64722497e-01, -2.23247072e-01, -6.96932194e-01,\n",
       "         1.63999718e+00,  1.96240726e+00, -2.13006796e-01,\n",
       "         8.20359711e-02, -4.07409537e-01, -7.72854071e-01,\n",
       "         1.76839111e+00, -5.53246033e-01, -1.20013322e-01,\n",
       "        -3.74581727e-01, -1.09395694e+00, -1.02310065e+00,\n",
       "        -5.62565302e-01, -5.90996554e-01, -5.31552886e-01,\n",
       "         4.77313634e-02, -5.52538004e-02, -1.49218864e-01,\n",
       "        -2.36896512e-01, -7.19385746e-02, -4.18949907e-01,\n",
       "        -4.08362552e-01, -8.82025689e-01, -1.97524579e-01,\n",
       "        -6.61071829e-01, -2.26871848e-01, -9.49001954e-01,\n",
       "        -5.10858519e-01, -5.27814727e-01, -5.42637599e-01,\n",
       "        -8.82571703e-02, -1.16577279e+00, -8.85319022e-01,\n",
       "        -9.12766938e-01, -6.11864640e-01, -1.14759424e+00,\n",
       "        -2.96212217e-01, -7.54080240e-01, -4.17462219e-01,\n",
       "        -5.82886575e-02, -3.79775844e-01, -5.29955627e-01,\n",
       "        -7.82669654e-01, -2.11623720e-01, -1.81275658e-01,\n",
       "        -5.54401972e-01, -4.35908211e-01, -8.77823757e-01,\n",
       "        -6.27683528e-02,  1.11426184e-02,  2.15284781e-01,\n",
       "         4.37617446e-01, -3.31462779e-02,  3.31896804e-01,\n",
       "         1.14130055e+00, -3.86853999e-01, -3.20142806e-01,\n",
       "         1.29374049e+00, -4.09055652e-01,  2.82825366e+00,\n",
       "        -5.61253100e-01,  6.26311767e-02, -4.05971123e-01,\n",
       "        -7.24394441e-01, -1.74269299e-01,  3.92836706e-01,\n",
       "        -6.54936956e-02,  1.10117201e+00,  3.78254692e-01,\n",
       "        -3.47451744e-01, -1.75949445e-01, -4.99583305e-01,\n",
       "        -5.19254433e-01, -6.35060765e-01, -9.06327883e-01,\n",
       "         1.71795406e+00, -2.35347930e-01, -1.25942657e-01,\n",
       "         2.27362659e-01, -6.67909725e-01, -6.25961061e-01,\n",
       "        -6.28475366e-02, -4.45745437e-01, -3.20332826e-01,\n",
       "        -4.54207748e-01,  5.94642045e-01,  8.52685531e-01,\n",
       "         1.96894913e-01, -8.56477589e-01, -5.29717319e-01,\n",
       "         1.79511011e-01, -4.89097290e-02, -5.97618871e-01,\n",
       "        -5.03027654e-01, -2.02566080e-02,  2.02641917e+00,\n",
       "         2.05293608e-01,  6.80123525e-02,  9.28144710e-01,\n",
       "        -5.92470504e-01, -5.15042678e-01, -9.34837677e-02,\n",
       "        -1.01106934e+00,  1.26240495e+00,  7.38536437e-02,\n",
       "        -1.31442060e-01,  1.77755045e+00,  1.43068196e+00,\n",
       "        -3.83413334e-01,  9.81313993e-03,  8.20694542e-01,\n",
       "         1.38696562e+00, -3.66962083e-01,  3.50556355e-01,\n",
       "        -1.25695452e-01, -6.35805584e-01,  1.83494335e-01,\n",
       "         8.39833993e-01, -1.75774096e-01, -5.71313846e-01,\n",
       "         6.10618365e-01, -6.06890593e-01,  1.93702176e+00,\n",
       "        -1.74487471e-01, -6.64702683e-01, -2.49143947e-01,\n",
       "         2.77530254e-01, -2.75811880e-01, -5.39138784e-01,\n",
       "        -2.41028609e-01,  2.11277569e-01,  1.07835463e+00,\n",
       "        -3.52721015e-01,  1.74150299e+00, -7.90435161e-01,\n",
       "        -2.71672764e-01,  4.88261817e-01, -3.40389871e-01,\n",
       "        -6.64230536e-01, -7.39433033e-01,  2.42379819e+00,\n",
       "         6.67257950e-01, -3.62360755e-01,  8.14264520e-01,\n",
       "        -1.33184474e-01, -7.47794245e-01,  5.41708950e-01,\n",
       "         1.38221349e-01, -4.52551278e-01,  2.18897916e+00,\n",
       "        -5.63140992e-01, -3.64108546e-01, -5.25808996e-01,\n",
       "        -8.23869207e-01, -6.94842212e-01, -6.46292594e-01,\n",
       "        -3.89589906e-02, -3.31474993e-01,  1.80359758e+00,\n",
       "        -9.50154727e-01,  1.22024568e+00, -7.65787203e-01,\n",
       "        -2.02921747e-01, -9.07431463e-02, -9.08295533e-01,\n",
       "         2.32044347e+00, -3.31140574e-01,  2.87503767e+00,\n",
       "        -3.83739275e-01, -8.78494100e-02, -4.84855766e-01,\n",
       "        -4.63538860e-01,  1.08548358e+00, -8.83232582e-01,\n",
       "        -4.85375775e-01, -9.28200132e-02, -1.77443228e-01,\n",
       "        -5.63069234e-01,  2.42651595e+00, -7.78635631e-01,\n",
       "        -8.40368650e-01, -7.60986780e-02,  1.00001117e+00,\n",
       "        -6.19067461e-01,  3.82166967e-02,  2.62818564e-01,\n",
       "        -4.93555070e-03, -5.25708705e-01,  2.84236408e-01,\n",
       "         2.66476852e+00, -6.79459609e-01, -8.62576734e-01,\n",
       "        -8.60700097e-01, -8.44052302e-02,  1.12451827e-02,\n",
       "         8.36395775e-02, -3.55027705e-01,  2.51602263e-01,\n",
       "         3.53983516e-01, -4.01169595e-01, -1.00612823e+00,\n",
       "        -7.04155164e-01, -1.10489152e-01, -8.43876189e-01,\n",
       "         1.06284832e+00, -2.79810933e-01, -5.29177573e-01,\n",
       "        -2.23758627e-01, -8.20584114e-01, -1.08058540e-01,\n",
       "        -3.27682644e-01,  3.03521141e-01, -2.90305940e-01,\n",
       "        -2.72481967e-01,  1.48736908e+00,  1.08774176e-01,\n",
       "         5.68941493e-01,  3.40074392e-01, -2.99979899e-01,\n",
       "        -3.60675458e-01,  1.58784966e+00, -5.70031879e-01,\n",
       "         3.29909753e-01, -3.12243754e-01, -9.46773788e-02,\n",
       "         1.40556522e-01, -1.06801533e-01, -2.88316587e-01,\n",
       "        -4.17390825e-01, -4.71121215e-01,  2.37774682e+00,\n",
       "        -6.83374815e-01, -3.86205974e-01, -5.18832170e-01,\n",
       "        -2.83788249e-01,  1.30013539e+00, -5.13733345e-01,\n",
       "         6.33783350e-01,  1.70998324e+00, -3.51489085e-01,\n",
       "        -5.92284671e-01,  1.53098278e+00,  2.69443532e-01,\n",
       "        -9.72812331e-01, -4.89017653e-02,  3.82131168e-01,\n",
       "        -5.83067218e-01, -7.05165772e-01, -1.23287378e-02,\n",
       "        -6.44517152e-01, -7.58984599e-01, -8.09538063e-01,\n",
       "        -8.52888628e-01, -6.74090524e-03,  1.11988157e+00,\n",
       "         4.48302035e-01,  3.75159113e-02,  1.60011549e-01,\n",
       "        -2.51993875e-02,  3.90644645e-02, -4.97218594e-01,\n",
       "        -3.27543895e-02, -8.20316299e-01, -2.70979752e-01,\n",
       "         1.05111425e-01,  1.13849059e+00, -1.71933263e-01,\n",
       "        -2.71713861e-01, -9.43803331e-01, -3.07915123e-01,\n",
       "         6.20293833e-01, -5.03579018e-01, -2.78919019e-01,\n",
       "        -3.76572236e-02,  1.91047947e+00, -4.89630030e-01,\n",
       "        -4.18511518e-01, -4.30402989e-01, -4.91038706e-01,\n",
       "         5.67521444e-01,  4.30542200e+00, -2.06543364e-01,\n",
       "        -6.72683660e-01, -7.97579049e-01, -3.33167798e-01,\n",
       "        -4.67270479e-01,  1.22827053e+00, -8.60080650e-01,\n",
       "        -6.11944438e-01, -4.14236898e-01, -7.52080148e-01,\n",
       "         5.72267694e-02,  2.85242202e-01,  1.50177575e+00,\n",
       "        -4.45288850e-01, -4.83209080e-01,  2.33697015e-01,\n",
       "         2.86757600e-01,  8.62325854e-02,  3.92090052e-01,\n",
       "        -2.29983385e-01, -6.68585852e-02,  2.80885291e-01,\n",
       "        -1.74564758e-01, -2.73908226e-02, -1.18505685e-01,\n",
       "        -8.03174829e-01, -1.70539281e-01,  1.14038234e+00,\n",
       "        -5.45207443e-01,  4.37521058e-02, -2.63856806e-01,\n",
       "         2.32838095e+00,  2.58920312e+00,  1.95128638e+00,\n",
       "        -6.31776942e-01, -7.00755759e-01,  2.76970024e-01,\n",
       "        -1.60980307e-02,  9.78430015e-02,  2.72375929e-01,\n",
       "        -5.55500656e-01, -5.12299068e-01,  6.72593118e-01,\n",
       "        -6.73980931e-01,  1.17963468e+00, -7.01704648e-02,\n",
       "        -7.39782854e-01,  5.43532165e-02, -6.24658855e-01,\n",
       "        -3.41720232e-01,  2.28061026e-01,  2.21568067e-01,\n",
       "         6.14878703e-04,  1.42468442e-01, -7.95093631e-01,\n",
       "        -4.44991056e-01,  1.07728214e+00, -4.97727415e-01,\n",
       "        -2.79270319e-01, -3.08635446e-01,  2.48429092e-02,\n",
       "        -3.33291710e-01, -4.43016803e-01, -1.10907000e-01,\n",
       "        -4.44811411e-01,  1.40570752e-01,  7.01606519e-01,\n",
       "         7.09886795e-01, -3.64474167e-01, -7.84869093e-01,\n",
       "        -1.07853933e+00, -2.48158566e-01,  8.04862735e-01,\n",
       "         2.65561225e-01, -4.76077161e-01, -1.14793803e-01,\n",
       "        -9.04397691e-02, -4.81141598e-01, -4.59092754e-02,\n",
       "        -2.78976268e-02, -6.81562853e-01, -3.86978143e-01,\n",
       "         1.95825159e+00, -5.87359602e-01,  1.96376774e+00,\n",
       "        -7.42381086e-01, -3.40612328e-02,  3.66964831e+00,\n",
       "        -3.52889639e-01, -6.70458575e-01,  2.64262892e-01,\n",
       "         6.12260798e-01,  1.48510479e-01,  4.76695305e-01,\n",
       "        -6.80037436e-01, -3.18400478e-01, -5.21984739e-01,\n",
       "        -4.24575461e-01,  7.32601251e-01, -2.80243922e-01,\n",
       "        -2.00054355e-01, -5.24939071e-01,  9.85130796e-01,\n",
       "         7.60854287e-01, -4.58618158e-01,  3.72704770e-03,\n",
       "        -6.65005214e-01, -2.81769569e-01, -2.81118683e-01,\n",
       "        -1.25288296e-01, -1.34597226e-01, -7.42231805e-01,\n",
       "        -5.33111215e-01,  1.40288814e+00,  1.98459605e+00,\n",
       "        -3.56241350e-01,  1.81705739e+00, -1.60223987e-01,\n",
       "        -3.06885085e-01, -6.71469346e-01, -2.71168747e-01,\n",
       "        -1.06866866e-01,  9.68826366e-02, -6.11875836e-01,\n",
       "        -2.98401972e-01,  2.09736477e-01,  3.05702943e-01,\n",
       "         2.18529308e-01, -2.42093733e-01, -6.71649386e-01,\n",
       "         3.84487873e-01, -2.39289271e-01, -5.37026992e-01,\n",
       "        -1.38251052e-01, -4.49809928e-01, -1.13110262e-01,\n",
       "         1.38762232e-01, -7.27880470e-01, -5.17569285e-01,\n",
       "        -2.37323265e-01, -4.59298808e-02, -9.38272680e-02,\n",
       "        -6.59726205e-01, -6.42324860e-01, -2.98866848e-01,\n",
       "        -2.62470590e-01,  7.06674271e-02, -3.45033459e-01,\n",
       "        -1.85761503e-01, -6.57247971e-01, -1.93537539e-01,\n",
       "        -3.32297240e-03,  6.56539460e-01, -6.57757460e-01,\n",
       "        -6.80175996e-02,  2.45431823e-01, -5.50646296e-01,\n",
       "        -2.11544332e-01,  1.16170110e+00, -3.41478846e-01,\n",
       "         2.51529042e-02, -2.13655400e-01,  5.87455446e-01,\n",
       "        -2.03655419e-01,  9.23367555e-02, -2.96477629e-03,\n",
       "        -6.46673898e-01, -5.48564518e-02, -1.24371284e-01,\n",
       "        -1.16218375e-02, -2.18384901e-01, -3.90332916e-01,\n",
       "         4.63746779e-01, -9.14875910e-01,  3.54359504e-01,\n",
       "        -6.89381493e-01, -1.23239464e-01,  1.39748952e-01,\n",
       "        -4.22477652e-01,  1.86556230e+00, -2.52864106e-01,\n",
       "        -2.70911664e-01,  1.00380845e+00,  2.30498915e-01,\n",
       "         2.01128210e+00,  8.89689622e-01, -1.87222077e-01,\n",
       "         1.72550248e-01, -5.61851926e-01,  4.83397143e-02,\n",
       "        -4.74885372e-01, -1.77692090e-01,  1.77003769e-01,\n",
       "        -3.74838269e-01,  1.13507155e+00, -8.45180475e-01,\n",
       "         3.40573093e-01, -7.94398966e-01, -3.10709988e-01,\n",
       "        -1.83566344e-01, -6.10689046e-01,  2.46507284e-01,\n",
       "        -2.57959352e-01, -4.02262674e-02, -3.79363118e-01,\n",
       "        -4.82365096e-01,  2.22460191e+00, -7.77576129e-01,\n",
       "        -7.00204989e-01,  2.32181917e+00, -9.09225729e-01,\n",
       "        -8.11797943e-01, -6.06390793e-01, -4.97446758e-01,\n",
       "        -5.87888860e-01, -9.47504663e-01,  1.31290952e+00,\n",
       "         1.18715497e-01,  3.87795840e-01, -4.93303147e-01,\n",
       "         1.59007297e+00, -1.31379400e-01, -1.53359688e-02,\n",
       "         1.67405273e-01, -1.58269221e-01,  3.86339517e-02,\n",
       "        -8.81966340e-02, -2.83920574e-02, -7.87629827e-02,\n",
       "        -7.84308967e-02,  2.06999868e-01,  5.12206407e-01,\n",
       "        -7.64486329e-01, -1.42091015e-02, -2.67611415e-01,\n",
       "         1.54469860e-01,  2.99632256e+00, -4.93608593e-01,\n",
       "         6.27495715e-01,  5.46821140e-02,  1.92059187e-01,\n",
       "        -7.65350987e-01, -3.44619751e-03,  7.62206544e-01,\n",
       "        -6.42635163e-01, -8.35533724e-02,  7.65596193e-01,\n",
       "        -3.50915838e-01, -8.04277526e-01, -6.46354176e-02,\n",
       "         1.61324194e-02, -7.58734155e-01, -1.03978140e+00,\n",
       "        -5.10994236e-01,  5.07007325e-03, -1.68572747e-01,\n",
       "         3.44440299e-01,  1.50694461e+00, -4.88073540e-01,\n",
       "        -1.91442351e-01, -2.33869673e-01,  2.20901889e-01,\n",
       "         9.81123307e-01,  8.95818509e-01, -1.40800516e-01,\n",
       "         1.65767505e+00, -2.76618735e-02, -1.23644206e-02,\n",
       "         2.95565147e-01,  5.66768122e-01, -5.92826840e-01,\n",
       "        -6.29827865e-01,  6.66766221e-01,  2.18792037e+00,\n",
       "        -2.91683503e-02, -7.34976482e-02, -2.28800134e-01,\n",
       "         1.23888834e-01, -2.37135252e-01, -4.62618373e-01,\n",
       "        -8.67964847e-01, -5.09438137e-01,  5.94181643e-02,\n",
       "        -5.53818704e-01, -5.93948938e-01, -5.63513768e-02,\n",
       "        -5.87828388e-01,  1.99254044e+00,  7.57582362e-01,\n",
       "        -5.43654199e-01, -2.58730469e-01, -7.46965266e-02,\n",
       "        -9.52241930e-03, -4.80308552e-01,  2.82358573e-01,\n",
       "        -7.08757882e-02, -3.66061690e-01,  2.98136076e-01,\n",
       "        -4.99120202e-01, -7.18566586e-01,  9.65506527e-01,\n",
       "        -4.37108666e-01, -1.45182804e-02, -4.54851035e-01,\n",
       "        -6.37173949e-01, -4.33321061e-02,  1.14664828e+00,\n",
       "        -3.12046722e-01, -3.27852796e-01, -2.06987676e-01,\n",
       "        -4.33420494e-01, -4.46615039e-01, -6.74699486e-02,\n",
       "        -1.09847070e+00,  4.86198801e-01,  4.49312969e-01,\n",
       "        -1.64177073e-01, -1.26280597e-02,  8.79649457e-01,\n",
       "         7.47853840e-01, -4.86468530e-01, -4.65739935e-01,\n",
       "        -1.22635676e-01,  4.43989714e-01, -4.16875282e-01,\n",
       "        -1.00409623e+00, -3.49472628e-01,  1.15461469e-01,\n",
       "         7.46938255e-01, -2.22924243e-01, -4.27113276e-01,\n",
       "         6.75253125e-01,  3.97236208e-02, -5.06099047e-01,\n",
       "        -6.84519664e-01, -5.81098140e-01, -2.98863686e-01,\n",
       "        -5.76985041e-02, -3.63446151e-01, -5.81925789e-01,\n",
       "        -3.70626703e-01, -4.69251361e-01,  9.38619628e-01,\n",
       "        -8.19724506e-01, -5.36071953e-01, -5.51783987e-01,\n",
       "        -4.07018448e-01, -7.33119976e-02, -8.44226843e-02,\n",
       "         1.06064094e+00,  1.91808726e-02, -2.74297576e-02,\n",
       "         1.65679851e+00, -3.29849481e-01, -6.68312304e-02,\n",
       "        -4.90501525e-03, -1.73881041e-01,  2.69511201e-01,\n",
       "        -9.54445864e-02, -1.99696941e-01,  9.89557090e-01,\n",
       "        -4.82139267e-01, -3.82787353e-01, -1.01937994e-01,\n",
       "        -8.34684532e-01, -4.37876003e-01, -1.06499020e-01,\n",
       "        -3.95388384e-01,  1.14260898e+00,  3.90462976e-01,\n",
       "        -6.04133567e-02, -4.62597814e-03, -4.26241006e-01,\n",
       "         1.57441881e+00, -6.21416861e-01,  2.51495090e-01,\n",
       "         1.78595092e+00,  1.44719170e+00,  6.75340735e-01,\n",
       "         6.63419598e-01, -2.69537519e-01,  2.58716347e+00,\n",
       "        -3.80032224e-01, -1.78609293e-02, -7.87056599e-02,\n",
       "         1.17403601e+00, -5.28324161e-01,  1.74734787e+00,\n",
       "         8.33999660e-01, -1.13816433e+00, -2.51699078e-01,\n",
       "         1.13905079e-01,  2.75975276e+00,  5.84670367e-02,\n",
       "         6.27734571e-01, -5.88322948e-01, -1.47384647e-03,\n",
       "         6.21814647e-01, -2.74309380e-02,  7.92776187e-01,\n",
       "         1.23012250e+00, -1.32111692e-01, -2.02498311e-02,\n",
       "        -2.90636426e-01,  5.82967886e-02, -5.81587950e-01,\n",
       "         3.40880069e-01,  1.63054928e-01, -8.36166464e-03,\n",
       "        -4.21827203e-01, -7.65006428e-04,  2.09660044e-01,\n",
       "        -3.36612151e-01, -6.19127807e-01,  4.79839906e-01,\n",
       "        -3.25874634e-01, -3.02596321e-01, -5.27368713e-01,\n",
       "         7.25158288e-01, -2.06542801e-01,  9.03653821e-01,\n",
       "        -1.12341780e+00, -1.78692524e-01, -6.74395309e-01,\n",
       "         1.51291279e+00,  4.12330156e-01,  2.83525905e-01,\n",
       "        -4.00036149e-01,  3.15540714e+00, -1.05245515e-01,\n",
       "        -4.82445821e-01, -2.66233754e-01, -2.81305193e-01,\n",
       "        -9.75263229e-01, -3.90922705e-01,  1.06654289e+00,\n",
       "         1.12595359e-01, -5.37963749e-01,  3.18751345e-01,\n",
       "         1.88432068e+00, -3.29749744e-01, -3.28584278e-01,\n",
       "        -7.19791939e-01, -1.24017840e+00, -2.03470551e-01,\n",
       "        -4.92517824e-01, -4.33758310e-02,  6.21879019e-01,\n",
       "        -1.45935756e-01, -5.46471179e-01, -4.30952288e-01,\n",
       "        -1.75220116e-01, -2.48803114e-01, -2.00837378e-01,\n",
       "        -1.64316479e-01,  5.33606221e-01, -2.42629385e-01,\n",
       "        -2.97138441e-01, -2.02432272e-01, -2.03814538e-01,\n",
       "         2.47674572e-01, -2.00619599e-01,  2.58884823e-01,\n",
       "         8.02719649e-02,  6.08295690e-01, -2.61316473e-01,\n",
       "         2.74424687e-01,  5.33777768e-01, -1.66842142e-01,\n",
       "        -2.45148981e-01, -2.57327778e-01,  4.97138256e-01,\n",
       "         8.70327136e-02, -1.44100728e-01, -1.67892823e-01,\n",
       "         1.40254089e-01, -2.33697470e-01, -1.83260881e-01,\n",
       "        -1.79381687e-01,  3.54820278e+00, -9.58274980e-01,\n",
       "        -3.00661098e+00,  4.12317960e-01]])"
      ]
     },
     "execution_count": 212,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model['classifier'].coef_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [],
   "source": [
    "LogisticRegressionProbs = model.predict_proba(df_test.drop(columns=not_useful+['late_order']))[:, 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.1243    , 0.14126935, 0.23928753, ..., 0.12044055, 0.38198951,\n",
       "       0.21665572])"
      ]
     },
     "execution_count": 155,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "LogisticRegressionProbs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_pred_LR = pd.DataFrame()\n",
    "df_pred_LR['order_id'] = df_test['order_id']\n",
    "df_pred_LR['late_order'] = LogisticRegressionProbs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_pred_LR.to_csv('pred_LogisticRegression4.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Papi DL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 406,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 332,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1024"
      ]
     },
     "execution_count": 332,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "d_model = len(x[0])\n",
    "\n",
    "class Net(nn.Module):\n",
    "    \"\"\"\n",
    "    Text classifier based on a pytorch TransformerEncoder.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(\n",
    "        self,\n",
    "        nhead=4,\n",
    "        dim_feedforward=1024,\n",
    "        num_layers=4,\n",
    "        dropout=0.1,\n",
    "        activation=\"relu\",\n",
    "        classifier_dropout=0.1,\n",
    "    ):\n",
    "\n",
    "        super().__init__()\n",
    "\n",
    "        encoder_layer = nn.TransformerEncoderLayer(\n",
    "            d_model=d_model,\n",
    "            nhead=nhead,\n",
    "            dim_feedforward=dim_feedforward,\n",
    "            dropout=dropout,\n",
    "            batch_first=True\n",
    "        )\n",
    "        self.transformer_encoder = nn.TransformerEncoder(\n",
    "            encoder_layer,\n",
    "            num_layers=num_layers,\n",
    "        )\n",
    "        self.classifier = nn.Linear(d_model, 1)\n",
    "        self.d_model = d_model\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.transformer_encoder(x)\n",
    "        x = torch.sigmoid(self.classifier(x))\n",
    "\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'x_train' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-117-488890a65da2>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0mepoch_correct\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0mepoch_count\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 5\u001b[1;33m \u001b[0mpredictions\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx_train\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mbatch\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0mbatch_size\u001b[0m \u001b[1;33m:\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[1;33m+\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      6\u001b[0m \u001b[0mlabels\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0my_train\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mbatch\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0mbatch_size\u001b[0m \u001b[1;33m:\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[1;33m+\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'x_train' is not defined"
     ]
    }
   ],
   "source": [
    "batch = 0\n",
    "epoch_loss = 0\n",
    "epoch_correct = 0\n",
    "epoch_count = 0\n",
    "predictions = model(x_train[batch*batch_size : (batch+1)*batch_size].to(device))\n",
    "labels = y_train[batch*batch_size : (batch+1)*batch_size].to(device)\n",
    "\n",
    "loss = criterion(predictions, labels)\n",
    "\n",
    "correct = predictions.round() == labels\n",
    "acc = correct.sum().item() / correct.size(0)\n",
    "\n",
    "epoch_correct += correct.sum().item()\n",
    "epoch_count += correct.size(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 357,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9052734375"
      ]
     },
     "execution_count": 357,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "epoch_correct / epoch_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "starting\n",
      "epoch=0\n",
      "epoch_loss=51.87281847000122\n",
      "epoch accuracy: 0.7938537163267291\n",
      "epoch=1\n",
      "epoch_loss=45.233750373125076\n",
      "epoch accuracy: 0.8235153701296979\n",
      "epoch=2\n",
      "epoch_loss=44.430546551942825\n",
      "epoch accuracy: 0.8265036380836185\n",
      "epoch=3\n",
      "epoch_loss=43.90933087468147\n",
      "epoch accuracy: 0.828775782652132\n"
     ]
    }
   ],
   "source": [
    "epochs = 4\n",
    "model = Net().to(device)\n",
    "\n",
    "criterion = nn.BCELoss()\n",
    "\n",
    "lr = 1e-4\n",
    "optimizer = torch.optim.Adam(\n",
    "    (p for p in model.parameters() if p.requires_grad), lr=lr\n",
    ")\n",
    "\n",
    "torch.manual_seed(0)\n",
    "\n",
    "batch_size=1024\n",
    "batches = math.ceil(len(x)/batch_size)\n",
    "\n",
    "print(\"starting\")\n",
    "for epoch in range(epochs):\n",
    "    print(f\"{epoch=}\")\n",
    "    epoch_loss = 0\n",
    "    epoch_correct = 0\n",
    "    epoch_count = 0\n",
    "    for batch in range(math.ceil(len(x)/batch_size)):\n",
    "        optimizer.zero_grad()\n",
    "        predictions = model(x[batch*batch_size : (batch+1)*batch_size].to(device))\n",
    "        labels = y[batch*batch_size : (batch+1)*batch_size].to(device)\n",
    "\n",
    "        loss = criterion(predictions, labels)\n",
    "\n",
    "        correct = predictions.round() == labels\n",
    "        acc = correct.sum().item() / correct.size(0)\n",
    "\n",
    "        epoch_correct += correct.sum().item()\n",
    "        epoch_count += correct.size(0)\n",
    "\n",
    "        epoch_loss += loss.item()\n",
    "\n",
    "        loss.backward()\n",
    "\n",
    "        optimizer.step()\n",
    "    \"\"\"\n",
    "        predictions = model(x_train[batch*batch_size : (batch+1)*batch_size].to(device))\n",
    "        labels = y_train[batch*batch_size : (batch+1)*batch_size].to(device)\n",
    "\n",
    "        loss = criterion(predictions, labels)\n",
    "\n",
    "        correct = predictions.round() == labels\n",
    "        acc = correct.sum().item() / correct.size(0)\n",
    "\n",
    "        epoch_correct += correct.sum().item()\n",
    "        epoch_count += correct.size(0)\n",
    "\n",
    "        epoch_loss += loss.item()\n",
    "\n",
    "        loss.backward()\n",
    "\n",
    "        optimizer.step()\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        test_epoch_loss = 0\n",
    "        test_epoch_correct = 0\n",
    "        test_epoch_count = 0\n",
    "\n",
    "        for batch in range(math.ceil(len(x_test)/batch_size)):\n",
    "            predictions = model(x_test[batch*batch_size : (batch+1)*batch_size].to(device))\n",
    "            labels = y_test[batch*batch_size : (batch+1)*batch_size].to(device)\n",
    "            test_loss = criterion(predictions, labels)\n",
    "\n",
    "            correct = predictions.round() == labels\n",
    "            acc = correct.sum().item() / correct.size(0)\n",
    "\n",
    "            test_epoch_correct += correct.sum().item()\n",
    "            test_epoch_count += correct.size(0)\n",
    "            test_epoch_loss += loss.item()\n",
    "\n",
    "    print(f\"{epoch_loss=}\")\n",
    "    print(f\"epoch accuracy: {epoch_correct / epoch_count}\")\n",
    "    print(f\"{test_epoch_loss=}\")\n",
    "    print(f\"test epoch accuracy: {test_epoch_correct / test_epoch_count}\")\n",
    "    \"\"\"\n",
    "    print(f\"{epoch_loss=}\")\n",
    "    print(f\"epoch accuracy: {epoch_correct / epoch_count}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model.state_dict(), 'PapiDL.model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "data = df_test.drop(columns=not_useful+['late_order'])\n",
    "\n",
    "k = np.squeeze(np.asarray(preprocessor.fit_transform(data).todense()))\n",
    "\n",
    "padding = np.zeros(1024-len(k[0]))\n",
    "\n",
    "z = []\n",
    "for i in range(len(k)):\n",
    "    z.append(list(np.concatenate((k[i], padding))))\n",
    "k = torch.tensor(z, dtype=torch.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds = []\n",
    "batch_size=128\n",
    "for batch in range(math.ceil(len(k)/batch_size)):\n",
    "    preds.append(model(k[batch*batch_size : (batch+1)*batch_size].to(device)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds = torch.cat(list(torch.cat(preds))).detach().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [],
   "source": [
    "def trans(num):\n",
    "    return 1 - num\n",
    "t = np.vectorize(trans)\n",
    "p = t(p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.25205749, 0.30069175, 0.09594342, ..., 0.16871293, 0.19298422,\n",
       "       0.08183663])"
      ]
     },
     "execution_count": 125,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_pred_DL = pd.DataFrame()\n",
    "df_pred_DL['order_id'] = df_test['order_id']\n",
    "df_pred_DL['late_order'] = p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_pred_DL.to_csv('pred_DL.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
